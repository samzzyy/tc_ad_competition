{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2SecondsFrom1970(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y-%m-%d %H:%M:%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return secondsFrom1970\n",
    "\n",
    "def seconds2Datetime(seconds_from_1970):\n",
    "    timeArray = time.localtime(seconds_from_1970)#1970秒数\n",
    "    otherStyleTime = time.strftime(\"%Y-%m-%d %H:%M:%S\", timeArray)\n",
    "    datetime1=datetime.datetime.strptime(otherStyleTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return str(datetime1)\n",
    "def datetime2SecondsFrom1970_s(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y%m%d%H%M%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return int(secondsFrom1970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 biger than 0: (4987, 109) equal 0: (11861, 109)\n",
      "6 biger than 0: (4453, 109) equal 0: (11701, 109)\n",
      "7 biger than 0: (4489, 109) equal 0: (10629, 109)\n",
      "8 biger than 0: (4785, 109) equal 0: (11009, 109)\n",
      "9 biger than 0: (4780, 109) equal 0: (9562, 109)\n",
      "10 biger than 0: (4759, 109) equal 0: (10244, 109)\n",
      "11 biger than 0: (4637, 109) equal 0: (10856, 109)\n",
      "12 biger than 0: (4763, 109) equal 0: (10364, 109)\n",
      "13 biger than 0: (4837, 109) equal 0: (10949, 109)\n",
      "14 biger than 0: (5090, 109) equal 0: (11247, 109)\n",
      "15 biger than 0: (5137, 109) equal 0: (12185, 109)\n",
      "16 biger than 0: (4257, 109) equal 0: (7132, 109)\n",
      "17 biger than 0: (4346, 109) equal 0: (7560, 109)\n",
      "18 biger than 0: (3511, 109) equal 0: (6561, 109)\n",
      "19 biger than 0: (4401, 109) equal 0: (8991, 109)\n"
     ]
    }
   ],
   "source": [
    "for day in range(5,20):\n",
    "    if day <10:\n",
    "        train_set_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+'030'+str(day)+'_feature1phase_train.csv')\n",
    "    else:\n",
    "        train_set_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+'03'+str(day)+'_feature1phase_train.csv')\n",
    "    print(day,\"biger than 0:\",train_set_date[train_set_date['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",train_set_date[train_set_date['exposure_times']<=0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_3_19[:2000][train_set_3_19['exposure_times']>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ad_static_feature=pd.read_csv(\"../Data/A_preliminary/testA/ad_static_feature.out\",header=None,sep='\\t',\n",
    "                             names=['ad_id','create_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size',\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_3_19=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0319_feature1phase_train.csv')\n",
    "valid_set_from_3_19=train_set_3_19[:2000]#设定验证集\n",
    "train_set_3_19=train_set_3_19[2000:]\n",
    "train_set_3_18=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0318_feature1phase_train.csv')\n",
    "train_set_3_17=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0317_feature1phase_train.csv')\n",
    "# train_set_3_17=train_set_3_17[train_set_3_17['exposure_times']>0]\n",
    "train_set_3_16=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0316_feature1phase_train.csv')\n",
    "# train_set_3_16=train_set_3_16[train_set_3_16['exposure_times']>0]\n",
    "train_set_3_15=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0315_feature1phase_train.csv')\n",
    "# train_set_3_15=train_set_3_15[train_set_3_15['exposure_times']>0]\n",
    "train_set_3_14=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0314_feature1phase_train.csv')\n",
    "# train_set_3_14=train_set_3_14[train_set_3_14['exposure_times']>0]\n",
    "train_set_3_13=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0313_feature1phase_train.csv')\n",
    "# train_set_3_13=train_set_3_13[train_set_3_13['exposure_times']>0]\n",
    "train_set_3_12=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0312_feature1phase_train.csv')\n",
    "# train_set_3_12=train_set_3_12[train_set_3_12['exposure_times']>0]\n",
    "train_set_3_11=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0311_feature1phase_train.csv')\n",
    "# train_set_3_11=train_set_3_11[train_set_3_11['exposure_times']>0]\n",
    "train_set_3_10=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0310_feature1phase_train.csv')\n",
    "# train_set_3_10=train_set_3_10[train_set_3_10['exposure_times']>0]\n",
    "train_set_3_09=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0309_feature1phase_train.csv')\n",
    "# train_set_3_09=train_set_3_09[train_set_3_09['exposure_times']>0]\n",
    "train_set_3_08=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0308_feature1phase_train.csv')\n",
    "train_set_3_07=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0307_feature1phase_train.csv')\n",
    "train_set_3_06=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0306_feature1phase_train.csv')\n",
    "train_set_3_05=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0305_feature1phase_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_3_19=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0319_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_19=train_set_3_19[2000:]\n",
    "# valid_set_from_3_19=train_set_3_19[:2000]#设定验证集\n",
    "# train_set_3_18=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0318_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_17=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0317_feature1phase_complexMedian_train.csv')\n",
    "# # train_set_3_17=train_set_3_17[train_set_3_17['exposure_times']>0]\n",
    "# train_set_3_16=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0316_feature1phase_complexMedian_train.csv')\n",
    "# # train_set_3_16=train_set_3_16[train_set_3_16['exposure_times']>0]\n",
    "# train_set_3_15=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0315_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_15=train_set_3_15[train_set_3_15['exposure_times']>0]\n",
    "# train_set_3_14=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0314_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_14=train_set_3_14[train_set_3_14['exposure_times']>0]\n",
    "# train_set_3_13=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0313_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_13=train_set_3_13[train_set_3_13['exposure_times']>0]\n",
    "# train_set_3_12=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0312_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_12=train_set_3_12[train_set_3_12['exposure_times']>0]\n",
    "# train_set_3_11=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0311_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_11=train_set_3_11[train_set_3_11['exposure_times']>0]\n",
    "# train_set_3_10=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0310_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_10=train_set_3_10[train_set_3_10['exposure_times']>0]\n",
    "# train_set_3_09=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0309_feature1phase_complexMedian_train.csv')\n",
    "# train_set_3_09=train_set_3_09[train_set_3_09['exposure_times']>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 218083 entries, 2000 to 16847\n",
      "Columns: 108 entries, ad_id to week_day\n",
      "dtypes: float64(46), int64(61), object(1)\n",
      "memory usage: 181.4+ MB\n",
      "train\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 218083 entries, 0 to 218082\n",
      "Columns: 110 entries, ad_id to have_create_seconds\n",
      "dtypes: float64(46), int64(63), object(1)\n",
      "memory usage: 184.7+ MB\n",
      "train\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 1999\n",
      "Columns: 110 entries, ad_id to create_time\n",
      "dtypes: float64(46), int64(63), object(1)\n",
      "memory usage: 1.7+ MB\n",
      "valid\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "train_set=pd.DataFrame([])\n",
    "train_set=pd.concat([train_set,train_set_3_19],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_18],axis=0)\n",
    "train_set['ad_trades_id']=train_set['ad_trades_id'].apply(lambda x: int(str(x).split(',')[0]))\n",
    "#3月18,19日两天有275条样本交易行业超过一个，但是test_sample中不存在这样的样本，直接取第一个\n",
    "train_set=pd.concat([train_set,train_set_3_17],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_16],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_15],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_14],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_13],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_12],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_11],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_10],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_09],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_08],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_07],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_06],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_05],axis=0)\n",
    "train_set.drop(columns='create_time',inplace=True)\n",
    "valid_set_from_3_19.drop(columns='create_time',inplace=True)\n",
    "print('train\\n',train_set.info())\n",
    "train_set=train_set.merge(ad_static_feature[['ad_id','create_time']],on='ad_id',how='inner')\n",
    "valid_set_from_3_19=valid_set_from_3_19.merge(ad_static_feature[['ad_id','create_time']],on='ad_id',how='inner')\n",
    "train_set['have_create_seconds']=train_set['end_time']-train_set['create_time']\n",
    "valid_set_from_3_19['have_create_seconds']=valid_set_from_3_19['end_time']-valid_set_from_3_19['create_time']\n",
    "print('train\\n',train_set.info())\n",
    "print('valid\\n',valid_set_from_3_19.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218083\n",
      "218083\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210787 entries, 0 to 210786\n",
      "Columns: 111 entries, index to have_create_seconds\n",
      "dtypes: float64(46), int64(64), object(1)\n",
      "memory usage: 178.5+ MB\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape[0])\n",
    "train_set.drop_duplicates(inplace=True)\n",
    "print(train_set.shape[0])#去重\n",
    "train_set=train_set[(train_set['hold_time']>10800)]#持续时间需要超过三个小时的样本\n",
    "# train_set=train_set[(train_set['audience_orientation_nums']>0)]#定向人群数量为0的是有问题的\n",
    "train_set.reset_index(inplace=True)\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "ad_sample_test=pd.read_csv('../Data/A_preliminary_generate/Test/ad_sample_feature1phase_test.csv')\n",
    "\n",
    "ad_sample_test['have_create_seconds']=0\n",
    "\n",
    "ad_sample_test['have_create_seconds'][\n",
    "    ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190319235959')]=datetime2SecondsFrom1970_s('20190320235959')-ad_sample_test['create_time'][ad_sample_test['create_time']\n",
    "                                                                                                                                                 <=datetime2SecondsFrom1970_s('20190319235959')]\n",
    "#预测3月20日周三\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190319235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190320235959'))]=datetime2SecondsFrom1970_s('20190321235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190319235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190320235959'))]\n",
    "#3月21日周四\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190320235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190321235959'))]=datetime2SecondsFrom1970_s('20190322235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190320235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190321235959'))]\n",
    "#3月22日周五\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190321235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190322235959'))]=datetime2SecondsFrom1970_s('20190323235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190321235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190322235959'))]\n",
    "#3月23日周六\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190322235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190323235959'))]=datetime2SecondsFrom1970_s('20190324235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190322235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190323235959'))]\n",
    "#3月24日周日\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190323235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190324235959'))]=datetime2SecondsFrom1970_s('20190325235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190323235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190324235959'))]\n",
    "#3月25日周一\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list=[\n",
    "# 'ad_id','audience_targeting','end_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size','hold_time',\n",
    "#  'create_time','sample_id', 'exposure_ad_id',\n",
    " 'bid','audience_orientation_nums','0000_0030','0030_0100','0100_0130','0130_0200','0200_0230','0230_0300','0300_0330',\n",
    "'0330_0400','0400_0430','0430_0500','0500_0530','0530_0600','0600_0630','0630_0700','0700_0730','0730_0800','0800_0830','0830_0900',\n",
    "'0900_0930','0930_1000','1000_1030','1030_1100','1100_1130','1130_1200','1200_1230','1230_1300','1300_1330','1330_1400','1400_1430','1430_1500',\n",
    "'1500_1530','1530_1600','1600_1630','1630_1700','1700_1730','1730_1800','1800_1830','1830_1900','1900_1930','1930_2000','2000_2030','2030_2100',\n",
    "'2100_2130','2130_2200','2200_2230','2230_2300','2300_2330','2330_2400',\n",
    "'ad_id_history_exposure_times','ad_id_bid_mean','ad_id_bid_var','ad_id_pctr_mean','ad_id_pctr_var','ad_id_quality_ecpm_mean',\n",
    "'ad_id_quality_ecpm_var','ad_id_total_ecpm_mean','ad_id_total_ecpm_var', \n",
    "'account_id_history_exposure_times','account_id_bid_mean','account_id_bid_var','account_id_pctr_mean','account_id_pctr_var',\n",
    "'account_id_quality_ecpm_mean','account_id_quality_ecpm_var','account_id_total_ecpm_mean','account_id_total_ecpm_var',\n",
    "'commodity_id_history_exposure_times','commodity_id_bid_mean','commodity_id_bid_var','commodity_id_pctr_mean','commodity_id_pctr_var',\n",
    "'commodity_id_quality_ecpm_mean','commodity_id_quality_ecpm_var','commodity_id_total_ecpm_mean','commodity_id_total_ecpm_var',\n",
    "'commodity_type_history_exposure_times','commodity_type_bid_mean','commodity_type_bid_var','commodity_type_pctr_mean',\n",
    "'commodity_type_pctr_var','commodity_type_quality_ecpm_mean','commodity_type_quality_ecpm_var','commodity_type_total_ecpm_mean',\n",
    "'commodity_type_total_ecpm_var',\n",
    "'trades_id_history_exposure_times','trades_id_bid_mean','trades_id_bid_var','trades_id_pctr_mean','trades_id_pctr_var',\n",
    "'trades_id_quality_ecpm_mean','trades_id_quality_ecpm_var','trades_id_total_ecpm_mean','trades_id_total_ecpm_var',\n",
    "'week_day','have_create_seconds']\n",
    "\n",
    "label=train_set['exposure_times']\n",
    "train=train_set[columns_list]\n",
    "test=ad_sample_test[columns_list]\n",
    "label_validtion=valid_set_from_3_19['exposure_times']\n",
    "validtion=valid_set_from_3_19[columns_list]\n",
    "\n",
    "label_valid_array=label_validtion.values\n",
    "validtion_array=validtion.values\n",
    "train_array=train.values\n",
    "label_array=label.values\n",
    "test_array=test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 62.4581\tvalid_1's rmse: 48.2879\n",
      "[400]\ttraining's rmse: 54.366\tvalid_1's rmse: 48.4334\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's rmse: 60.2235\tvalid_1's rmse: 47.9505\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 60.6919\tvalid_1's rmse: 70.6218\n",
      "[400]\ttraining's rmse: 53.9255\tvalid_1's rmse: 67.9279\n",
      "[600]\ttraining's rmse: 49.2499\tvalid_1's rmse: 65.9141\n",
      "[800]\ttraining's rmse: 45.7872\tvalid_1's rmse: 64.7273\n",
      "[1000]\ttraining's rmse: 43.0254\tvalid_1's rmse: 63.5814\n",
      "[1200]\ttraining's rmse: 40.7576\tvalid_1's rmse: 62.6906\n",
      "[1400]\ttraining's rmse: 38.8587\tvalid_1's rmse: 61.9815\n",
      "[1600]\ttraining's rmse: 37.2727\tvalid_1's rmse: 61.6343\n",
      "[1800]\ttraining's rmse: 35.8451\tvalid_1's rmse: 61.3182\n",
      "[2000]\ttraining's rmse: 34.5568\tvalid_1's rmse: 60.9944\n",
      "[2200]\ttraining's rmse: 33.4174\tvalid_1's rmse: 60.831\n",
      "[2400]\ttraining's rmse: 32.3562\tvalid_1's rmse: 60.6466\n",
      "Early stopping, best iteration is:\n",
      "[2332]\ttraining's rmse: 32.6979\tvalid_1's rmse: 60.6081\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 61.3003\tvalid_1's rmse: 62.3604\n",
      "[400]\ttraining's rmse: 54.286\tvalid_1's rmse: 59.4152\n",
      "[600]\ttraining's rmse: 49.7163\tvalid_1's rmse: 58.0028\n",
      "[800]\ttraining's rmse: 46.0248\tvalid_1's rmse: 57.0692\n",
      "[1000]\ttraining's rmse: 43.1512\tvalid_1's rmse: 56.5587\n",
      "[1200]\ttraining's rmse: 40.7507\tvalid_1's rmse: 56.5877\n",
      "Early stopping, best iteration is:\n",
      "[1059]\ttraining's rmse: 42.384\tvalid_1's rmse: 56.5162\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 52.6898\tvalid_1's rmse: 95.9519\n",
      "[400]\ttraining's rmse: 46.0912\tvalid_1's rmse: 92.4374\n",
      "[600]\ttraining's rmse: 41.7901\tvalid_1's rmse: 91.7474\n",
      "[800]\ttraining's rmse: 38.3366\tvalid_1's rmse: 91.0264\n",
      "[1000]\ttraining's rmse: 35.6747\tvalid_1's rmse: 90.8361\n",
      "[1200]\ttraining's rmse: 33.4729\tvalid_1's rmse: 90.7779\n",
      "[1400]\ttraining's rmse: 31.6487\tvalid_1's rmse: 90.5591\n",
      "[1600]\ttraining's rmse: 30.0956\tvalid_1's rmse: 90.3277\n",
      "[1800]\ttraining's rmse: 28.7566\tvalid_1's rmse: 90.2165\n",
      "[2000]\ttraining's rmse: 27.6296\tvalid_1's rmse: 90.1373\n",
      "[2200]\ttraining's rmse: 26.5982\tvalid_1's rmse: 90.3255\n",
      "Early stopping, best iteration is:\n",
      "[2002]\ttraining's rmse: 27.6196\tvalid_1's rmse: 90.1142\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 63.7699\tvalid_1's rmse: 44.5468\n",
      "[400]\ttraining's rmse: 55.6219\tvalid_1's rmse: 42.4417\n",
      "[600]\ttraining's rmse: 50.502\tvalid_1's rmse: 41.622\n",
      "[800]\ttraining's rmse: 46.6765\tvalid_1's rmse: 41.3343\n",
      "[1000]\ttraining's rmse: 43.8145\tvalid_1's rmse: 41.2689\n",
      "[1200]\ttraining's rmse: 41.5763\tvalid_1's rmse: 41.171\n",
      "[1400]\ttraining's rmse: 39.7686\tvalid_1's rmse: 41.1051\n",
      "[1600]\ttraining's rmse: 38.2121\tvalid_1's rmse: 40.9992\n",
      "[1800]\ttraining's rmse: 36.8361\tvalid_1's rmse: 40.9797\n",
      "Early stopping, best iteration is:\n",
      "[1645]\ttraining's rmse: 37.8812\tvalid_1's rmse: 40.9233\n",
      "CV score: 3792.38458008\n",
      "validation: 17941.2388918868\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_lgb = np.zeros(train_array.shape[0])\n",
    "predictions_lgb = np.zeros(test_array.shape[0])\n",
    "valid_lgb=np.zeros(len(label_valid_array))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = lgb.Dataset(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    num_round = 10000*(fold_+1)\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(train_array[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test_array, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    valid_lgb += clf.predict(validtion_array, ntree_limit=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, label_array)))\n",
    "print('validation:',mean_squared_error(valid_lgb, label_valid_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample=pd.read_csv(\"../Data/A_preliminary/testA/test_sample.dat\",header=None,sep='\\t',\n",
    "                        names=['sample_id','ad_id','create_time','ad_size','ad_trades_id','commodity_type','commodity_id','ad_account_id',\n",
    "                              'when_ad_put','audience_targeting','bid'])\n",
    "print(test_sample.head())\n",
    "submission=test_sample[['sample_id','ad_id','bid']]\n",
    "# submission.insert(submission.shape[1], 'predict_exposure', predictions_xgb)\n",
    "submission.insert(submission.shape[1], 'predict_exposure', predictions_lgb)\n",
    "\n",
    "submission['predict_exposure']=submission['predict_exposure'].apply(lambda x : round(x,4))\n",
    "ad_id_exposure_predic=submission.groupby(['ad_id'])['predict_exposure'].aggregate(['mean','max','min']).reset_index()\n",
    "ad_id_dict={}\n",
    "for ad_id,mean,min_,max_ in zip(ad_id_exposure_predic['ad_id'],ad_id_exposure_predic['mean'],ad_id_exposure_predic['min'],ad_id_exposure_predic['max']):\n",
    "#     ad_id_dict[ad_id]=mean-(max_-min_)/8\n",
    "    ad_id_dict[ad_id]=mean\n",
    "#     ad_id_dict[ad_id]=max_\n",
    "\n",
    "\n",
    "print('how many ad_id exposure less 1 times :')\n",
    "nums=0\n",
    "for _ in ad_id_dict.values():\n",
    "    if _ < 1:\n",
    "        nums+=1\n",
    "print(nums)\n",
    "\n",
    "print('Monotonic !!!')\n",
    "ad_id_explosure_df=pd.DataFrame({\"ad_id\":list(ad_id_dict.keys()),\"explosion_init\":list(ad_id_dict.values())})\n",
    "submission_csv=test_sample[['sample_id','ad_id','bid']][:]\n",
    "submission_csv=submission_csv.merge(ad_id_explosure_df,on='ad_id',how='outer')\n",
    "submission_csv['explosion']=submission_csv['explosion_init']+submission_csv['bid']/1000\n",
    "submission_csv['explosion']=submission_csv['explosion'].apply(lambda x:round(x,4))\n",
    "# submission_csv[['sample_id','explosion']].to_csv('submission.csv',header=None,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:73.4595\tvalid_data-rmse:141.799\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:53.5301\tvalid_data-rmse:123.878\n",
      "[200]\ttrain-rmse:40.4405\tvalid_data-rmse:113.348\n",
      "[300]\ttrain-rmse:31.473\tvalid_data-rmse:107.109\n",
      "[400]\ttrain-rmse:25.3298\tvalid_data-rmse:103.783\n",
      "[500]\ttrain-rmse:21.0842\tvalid_data-rmse:101.705\n",
      "[600]\ttrain-rmse:17.951\tvalid_data-rmse:100.474\n",
      "[700]\ttrain-rmse:15.7365\tvalid_data-rmse:99.7251\n",
      "[800]\ttrain-rmse:14.1074\tvalid_data-rmse:99.4716\n",
      "[900]\ttrain-rmse:12.8835\tvalid_data-rmse:99.344\n",
      "[1000]\ttrain-rmse:12.0122\tvalid_data-rmse:99.2739\n",
      "[1100]\ttrain-rmse:11.3626\tvalid_data-rmse:99.3126\n",
      "[1200]\ttrain-rmse:10.8669\tvalid_data-rmse:99.3479\n",
      "Stopping. Best iteration:\n",
      "[1028]\ttrain-rmse:11.8171\tvalid_data-rmse:99.2655\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:93.9913\tvalid_data-rmse:79.5395\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:68.9123\tvalid_data-rmse:68.1416\n",
      "[200]\ttrain-rmse:51.8816\tvalid_data-rmse:62.6775\n",
      "[300]\ttrain-rmse:39.9607\tvalid_data-rmse:60.1482\n",
      "[400]\ttrain-rmse:31.7097\tvalid_data-rmse:58.9948\n",
      "[500]\ttrain-rmse:25.8314\tvalid_data-rmse:58.5705\n",
      "[600]\ttrain-rmse:21.4246\tvalid_data-rmse:58.5269\n",
      "[700]\ttrain-rmse:18.2658\tvalid_data-rmse:58.6747\n",
      "Stopping. Best iteration:\n",
      "[561]\ttrain-rmse:22.9477\tvalid_data-rmse:58.4997\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:95.3676\tvalid_data-rmse:72.2744\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:69.1102\tvalid_data-rmse:57.779\n",
      "[200]\ttrain-rmse:51.918\tvalid_data-rmse:52.2912\n",
      "[300]\ttrain-rmse:39.868\tvalid_data-rmse:51.5721\n",
      "[400]\ttrain-rmse:31.3429\tvalid_data-rmse:52.274\n",
      "Stopping. Best iteration:\n",
      "[283]\ttrain-rmse:41.6522\tvalid_data-rmse:51.4401\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:96.0513\tvalid_data-rmse:68.4695\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:70.383\tvalid_data-rmse:51.0889\n",
      "[200]\ttrain-rmse:53.4307\tvalid_data-rmse:41.729\n",
      "[300]\ttrain-rmse:41.5949\tvalid_data-rmse:37.1134\n",
      "[400]\ttrain-rmse:33.0011\tvalid_data-rmse:35.6413\n",
      "[500]\ttrain-rmse:26.886\tvalid_data-rmse:35.5397\n",
      "[600]\ttrain-rmse:22.5131\tvalid_data-rmse:36.0786\n",
      "Stopping. Best iteration:\n",
      "[445]\ttrain-rmse:29.9756\tvalid_data-rmse:35.459\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:95.2715\tvalid_data-rmse:73.2438\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:69.5219\tvalid_data-rmse:58.04\n",
      "[200]\ttrain-rmse:52.2852\tvalid_data-rmse:50.0779\n",
      "[300]\ttrain-rmse:39.9817\tvalid_data-rmse:46.1379\n",
      "[400]\ttrain-rmse:31.4019\tvalid_data-rmse:44.4505\n",
      "[500]\ttrain-rmse:25.3773\tvalid_data-rmse:43.6593\n",
      "[600]\ttrain-rmse:21.143\tvalid_data-rmse:43.4394\n",
      "[700]\ttrain-rmse:18.1721\tvalid_data-rmse:43.4723\n",
      "[800]\ttrain-rmse:15.8937\tvalid_data-rmse:43.585\n",
      "Stopping. Best iteration:\n",
      "[635]\ttrain-rmse:20.0044\tvalid_data-rmse:43.3975\n",
      "\n",
      "CV score: 3812.55178591\n",
      "validation: 25616.01751681485\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 10}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb = np.zeros(len(train_array))\n",
    "predictions_xgb = np.zeros(len(test_array))\n",
    "valid_xgb=np.zeros(len(label_valid_array))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = xgb.DMatrix(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200,\n",
    "                    verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(train_array[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(test_array), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    valid_xgb += clf.predict(xgb.DMatrix(validtion_array), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, label_array)))\n",
    "print('validation:',mean_squared_error(valid_xgb, label_valid_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_id   ad_id  create_time  ad_size  ad_trades_id  commodity_type  \\\n",
      "0          1  394352   1529648412       34            84              13   \n",
      "1          2  585401   1553076190       40           221               1   \n",
      "2          3  419408   1553031394       30           122              13   \n",
      "3          4  405326   1553238836       64           136               1   \n",
      "4          5  578942   1541191585       34            12              13   \n",
      "\n",
      "   commodity_id  ad_account_id  \\\n",
      "0         29663          26657   \n",
      "1            -1           6262   \n",
      "2         32110          17436   \n",
      "3            -1          22359   \n",
      "4          6372          24082   \n",
      "\n",
      "                                         when_ad_put  \\\n",
      "0  281474976645120,281474976645120,28147497664512...   \n",
      "1  281474976579587,281474976579587,28147497657958...   \n",
      "2  17592185782272,17592185782272,17592185782272,1...   \n",
      "3  281474976694272,281474976694272,28147497669427...   \n",
      "4  68719214592,68719214592,68719214592,6871921459...   \n",
      "\n",
      "                                  audience_targeting  bid  \n",
      "0  age:819,608,988,741,202,837,400,394,942,361,72...  120  \n",
      "1  age:819,433,479,741,229,347,522,79,753,601|edu...   42  \n",
      "2                                                all    6  \n",
      "3  age:333,1|gender:2|area:11505,1874,3790,4566,5...  181  \n",
      "4  age:819,608,988,741,202,837,400,394,942,361,72...   31  \n",
      "how many ad_id exposure less 1 times :\n",
      "794\n",
      "Monotonic !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_sample=pd.read_csv(\"../Data/A_preliminary/testA/test_sample.dat\",header=None,sep='\\t',\n",
    "                        names=['sample_id','ad_id','create_time','ad_size','ad_trades_id','commodity_type','commodity_id','ad_account_id',\n",
    "                              'when_ad_put','audience_targeting','bid'])\n",
    "print(test_sample.head())\n",
    "submission=test_sample[['sample_id','ad_id','bid']]\n",
    "submission.insert(submission.shape[1], 'predict_exposure', predictions_xgb)\n",
    "# submission.insert(submission.shape[1], 'predict_exposure', predictions_lgb)\n",
    "\n",
    "submission['predict_exposure']=submission['predict_exposure'].apply(lambda x : round(x,4))\n",
    "ad_id_exposure_predic=submission.groupby(['ad_id'])['predict_exposure'].aggregate(['mean','max','min']).reset_index()\n",
    "ad_id_dict={}\n",
    "for ad_id,mean,min_,max_ in zip(ad_id_exposure_predic['ad_id'],ad_id_exposure_predic['mean'],ad_id_exposure_predic['min'],ad_id_exposure_predic['max']):\n",
    "#     ad_id_dict[ad_id]=mean-(max_-min_)/8\n",
    "    ad_id_dict[ad_id]=mean\n",
    "#     ad_id_dict[ad_id]=max_\n",
    "\n",
    "\n",
    "print('how many ad_id exposure less 1 times :')\n",
    "nums=0\n",
    "for _ in ad_id_dict.values():\n",
    "    if _ < 1:\n",
    "        nums+=1\n",
    "print(nums)\n",
    "\n",
    "print('Monotonic !!!')\n",
    "ad_id_explosure_df=pd.DataFrame({\"ad_id\":list(ad_id_dict.keys()),\"explosion_init\":list(ad_id_dict.values())})\n",
    "submission_csv=test_sample[['sample_id','ad_id','bid']][:]\n",
    "submission_csv=submission_csv.merge(ad_id_explosure_df,on='ad_id',how='outer')\n",
    "submission_csv['explosion']=submission_csv['explosion_init']+submission_csv['bid']/1000\n",
    "submission_csv['explosion']=submission_csv['explosion'].apply(lambda x:round(x,4))\n",
    "# submission_csv[['sample_id','explosion']].to_csv('submission.csv',header=None,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.116890349926063"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_csv['explosion'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv[['sample_id','explosion']].to_csv('submission.csv',header=None,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time,datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2SecondsFrom1970(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y-%m-%d %H:%M:%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return secondsFrom1970\n",
    "\n",
    "def seconds2Datetime(seconds_from_1970):\n",
    "    timeArray = time.localtime(seconds_from_1970)#1970秒数\n",
    "    otherStyleTime = time.strftime(\"%Y-%m-%d %H:%M:%S\", timeArray)\n",
    "    datetime1=datetime.datetime.strptime(otherStyleTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return str(datetime1)\n",
    "def datetime2SecondsFrom1970_s(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y%m%d%H%M%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return int(secondsFrom1970)\n",
    "def self_split_by_comma(str_):\n",
    "    return str_.split(',')\n",
    "def self_split_by_long(str_):\n",
    "    return str_.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extract Phase2\n",
    "## 1 人群定向 get_dummies()\n",
    "   人群定向有设定的,把设定的项的数量 \"age\":191,201,304 则age_item_nums=3\n",
    "## 2 按ad_id历史曝光平均次数\n",
    "\n",
    "## 3 将ad_size groupby 求mean&var of bid,pctr,quality_ecpm,total_ecpm （暂时先不要）\n",
    "\n",
    "## 4 按ad_id统计前一天的广告曝光量\n",
    "   不存在的按中位数填充\n",
    "## 5 目标人群的质量分数\n",
    "   操作步骤：\n",
    "   （1）3月19日前，每个用户看过的广告数量的总值。（对exposure groupby(user_id).aggrate('size')之后和user_data merge）\n",
    "   （2）按照“audience_orientation_nums”特征方式找到相应的人群，对相应的人群的广告数量进行sum,mean,max,min,median的统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data_user_id_watch_all_ad_nums_ready():\n",
    "    print('load total exposure log')\n",
    "    totalExposureLog=pd.read_csv(\"../Data/A_preliminary/testA/totalExposureLog.out\",header=None,sep='\\t',\n",
    "                        names=['request_id','ad_request_time','ad_position','user_id','exposure_ad_id','exposure_ad_size','bid','pctr',\n",
    "                                            'quality_ecpm','total_ecpm'])\n",
    "    df_user_id_watch_ad_nums=totalExposureLog.groupby('user_id')['request_id'].aggregate(['size']).reset_index()\n",
    "    df_user_id_watch_ad_nums.rename(columns={'size':'user_id_watch_all_ad_nums'},inplace=True)\n",
    "#     del totalExposureLog\n",
    "#     gc.collect()\n",
    "    print('load user data')\n",
    "    user_data=pd.read_csv(\"../Data/A_preliminary/testA/user_data\",header=None,sep='\\t',\n",
    "                              names=['user_id','age','gender','area','status','education','consuption_ability','device','work','connection_type','behavior'])\n",
    "    print('load data finished')\n",
    "\n",
    "    print(user_data.info())\n",
    "    user_data=user_data.merge(df_user_id_watch_ad_nums,on='user_id',how='left')\n",
    "    user_data.fillna(0,inplace=True)\n",
    "    print(user_data.info())\n",
    "    print('user_id history exposure times compute finished')\n",
    "\n",
    "    user_data['area']=user_data['area'].apply(self_split_by_comma)\n",
    "    user_data['status']=user_data['status'].apply(self_split_by_comma)\n",
    "    user_data['work']=user_data['work'].apply(self_split_by_comma)\n",
    "    user_data['behavior']=user_data['behavior'].apply(lambda x: self_split_by_comma(x)[:10])\n",
    "    return user_data,totalExposureLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_exposure_times_mean(date_train_extract):\n",
    "    print('history_exposure_times_mean')\n",
    "    df_train_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_feature1phase_train.csv')\n",
    "    ad_static_feature=pd.read_csv(\"../Data/A_preliminary/testA/ad_static_feature.out\",header=None,sep='\\t',\n",
    "                             names=['ad_id','create_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size',\n",
    "                             ])\n",
    "    df_train_date.rename(columns={'create_time':'start_time'},inplace=True)\n",
    "    df_train_date=df_train_date.merge(ad_static_feature[['ad_id','create_time']],on='ad_id',how='inner')\n",
    "    df_train_date['have_create_seconds']=df_train_date['end_time']-df_train_date['create_time']\n",
    "    df_train_date['have_create_days']=df_train_date['have_create_seconds']//86400+1\n",
    "    df_train_date['history_exposure_times_mean']=df_train_date['ad_id_history_exposure_times']/df_train_date['have_create_days']\n",
    "\n",
    "    del ad_static_feature\n",
    "    gc.collect()\n",
    "    return df_train_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audience_target_item_nums(df_train_date):\n",
    "    print('audience_target_item_nums')\n",
    "    df_train_date['audience_targeting']=df_train_date['audience_targeting'].apply(self_split_by_long)\n",
    "    audience_target_dict={'age':[],'gender':[],'area':[],'status':[],'education':[],'consuption_ability':[],\n",
    "                              'device':[],'work':[],'connection_type':[],'behavior':[]}\n",
    "    for sample_index,audience_targeting_list in zip(df_train_date.index,df_train_date['audience_targeting']):\n",
    "        if audience_targeting_list[0]=='all':#定向为全体人群时\n",
    "            for key in audience_target_dict.keys():\n",
    "                audience_target_dict[key].append(0)\n",
    "            continue\n",
    "        target_type_content_dict={}\n",
    "        for target_type_content in audience_targeting_list:\n",
    "            target_type_content_list=target_type_content.split(':')\n",
    "            target_type_content_dict[target_type_content_list[0]]=target_type_content_list[1].split(',')\n",
    "            #如{'age':[787,753,601,202,229,333,741,819,479,608,433,394], 'gender':2}所有的定向要求变成dict，方便查询\n",
    "        for key in audience_target_dict.keys():\n",
    "            audience_target_dict[key].append(len(target_type_content_dict.get(key,[])))\n",
    "    df_audience_target=pd.DataFrame(audience_target_dict)\n",
    "    df_audience_target.rename(columns={'age':'age_item_nums','gender':'gender_item_nums','area':'area_item_nums','status':'status_item_nums',\n",
    "             'education':'education_item_nums','consuption_ability':'consuption_ability_item_nums','device':'device_item_nums',\n",
    "            'work':'work_item_nums','connection_type':'connection_type_item_nums','behavior':'behavior_item_nums'},inplace=True)\n",
    "    df_train_date=pd.concat([df_train_date,df_audience_target],axis=1)\n",
    "    return df_train_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_before_exposure_times(df_train_date,date_before_day_train_extract,date_before_two_day_train_extract,totalExposureLog):\n",
    "    print('day_before_exposure_times')\n",
    "    train_date_train_extract_exposurelog=totalExposureLog[\n",
    "            (totalExposureLog['ad_request_time']>datetime2SecondsFrom1970_s('2019'+date_before_two_day_train_extract+'235959')) & \n",
    "            (totalExposureLog['ad_request_time']<=datetime2SecondsFrom1970_s('2019'+date_before_day_train_extract+'235959'))]\n",
    "    train_date_train_extract_exposurelog.index=range(train_date_train_extract_exposurelog.shape[0])\n",
    "        #训练集提取日期 date_train_extract  ！！！前一天的！！！ 曝光日志找出来。\n",
    "\n",
    "    df_ad_id_beforeday_exposure_times=train_date_train_extract_exposurelog.groupby('exposure_ad_id')['user_id'].aggregate(['size']).reset_index()\n",
    "    df_ad_id_beforeday_exposure_times.rename(columns={'size':'day_before_exposure_times'},inplace=True)\n",
    "    df_train_date=df_train_date.merge(df_ad_id_beforeday_exposure_times,on='exposure_ad_id',how='left')\n",
    "    df_train_date.fillna(0,inplace=True)\n",
    "    return df_train_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_watch_ad_nums_sum_mean_var_max_min_median(df_train_date,user_data):\n",
    "    print('user_id_watch_ad_nums_sum_mean_var_max_min_median')\n",
    "    all_audience_watch_ad_sum_mean_var_max_min_median_list=[]\n",
    "    all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].sum(),2))\n",
    "    all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].mean(),2))\n",
    "    all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].var(),2))\n",
    "    all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].max(),2))\n",
    "    all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].median(),2))\n",
    "    print(all_audience_watch_ad_sum_mean_var_max_min_median_list)\n",
    "    print('load audience_targeting_type_nums_dict.json file ...')\n",
    "    #相同的定向人群不用再去user_data中一一比对，用一个字典存储，有大量重复定向人群\n",
    "    if os.path.exists(\"audience_targeting_type_nums_dict.json\"):\n",
    "        f=open(\"audience_targeting_type_nums_dict.json\",\"r\")\n",
    "        data=list()\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "        f.close()\n",
    "        audience_targeting_type_nums_dict=data[0]\n",
    "    else:\n",
    "        audience_targeting_type_nums_dict={}\n",
    "    watch_ad_sum=[]\n",
    "    watch_ad_mean=[]\n",
    "    watch_ad_var=[]\n",
    "    watch_ad_max=[]\n",
    "    watch_ad_median=[]\n",
    "    for sample_index,audience_targeting_list in zip(df_train_date.index,df_train_date['audience_targeting']):\n",
    "        print(sample_index)\n",
    "        if audience_targeting_list[0]=='all':#定向为全体人群时\n",
    "            watch_ad_sum.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[0])\n",
    "            watch_ad_mean.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[1])\n",
    "            watch_ad_var.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[2])\n",
    "            watch_ad_max.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[3])\n",
    "            watch_ad_median.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[4])\n",
    "            print(all_audience_watch_ad_sum_mean_var_max_min_median_list)\n",
    "            continue\n",
    "        audience_targeting_str='|'.join(audience_targeting_list)\n",
    "        if audience_targeting_str in audience_targeting_type_nums_dict:\n",
    "            #有定向要求相同的、不同出价的广告样本，以及同类型的定向人群相同的广告样本。不需要再去数一次，存入一个dict中，若相同直接载入\n",
    "            watch_ad_sum.append(audience_targeting_type_nums_dict[audience_targeting_str][0])\n",
    "            watch_ad_mean.append(audience_targeting_type_nums_dict[audience_targeting_str][1])\n",
    "            watch_ad_var.append(audience_targeting_type_nums_dict[audience_targeting_str][2])\n",
    "            watch_ad_max.append(audience_targeting_type_nums_dict[audience_targeting_str][3])\n",
    "            watch_ad_median.append(audience_targeting_type_nums_dict[audience_targeting_str][4])\n",
    "            print(audience_targeting_type_nums_dict[audience_targeting_str])\n",
    "            continue\n",
    "        else:\n",
    "            target_type_content_dict={}\n",
    "            for target_type_content in audience_targeting_list:\n",
    "                target_type_content_list=target_type_content.split(':')\n",
    "                target_type_content_dict[target_type_content_list[0]]=target_type_content_list[1].split(',')\n",
    "                #如{'age':[787,753,601,202,229,333,741,819,479,608,433,394], 'gender':2}所有的定向要求变成dict，方便查询\n",
    "            user_data['check']=True#新的check列，符合要求为True，否则False\n",
    "            for target_check in target_type_content_dict.keys():\n",
    "                if target_check =='age':\n",
    "                    temp_set=set(target_type_content_dict['age'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['age'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "                elif target_check =='gender':\n",
    "                    temp_set=set(target_type_content_dict['gender'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['gender'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "                elif target_check =='education':\n",
    "                    temp_set=set(target_type_content_dict['education'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['education'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "                elif target_check =='consuption_ability':\n",
    "                    temp_set=set(target_type_content_dict['consuption_ability'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['consuption_ability'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "                elif target_check =='device':\n",
    "                    temp_set=set(target_type_content_dict['device'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['device'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "                elif target_check =='connection_type':\n",
    "                    temp_set=set(target_type_content_dict['connection_type'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['connection_type'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "                #以上字段,用户属性只能一个的，如最高教育程度等，按定向要求的分组互相取并集获得check列\n",
    "                elif target_check=='area':\n",
    "                    temp_set=set(target_type_content_dict['area'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['area'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "        #             print('area_check',sum(user_data['area_check']))\n",
    "                elif target_check=='status':\n",
    "                    temp_set=set(target_type_content_dict['status'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['status'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "        #             print('status_check',sum(user_data['status_check']))\n",
    "                elif target_check=='work':\n",
    "                    temp_set=set(target_type_content_dict['work'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['work'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "                elif target_check=='behavior':\n",
    "                    temp_set=set(target_type_content_dict['behavior'])\n",
    "                    user_data['check']=(user_data['check'])&(user_data['behavior'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "                #这部分字段属于 用户属性可以有多个，同时定向要求可以有多个，将每项两部分作为set取交，交集不为空即符合check，=1\n",
    "            temp_sum_mean_var_max_min_median=[]\n",
    "            temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].sum(),2))\n",
    "            temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].mean(),2))\n",
    "            temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].var(),2))\n",
    "            temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].max(),2))\n",
    "            temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].median(),2))\n",
    "\n",
    "            watch_ad_sum.append(temp_sum_mean_var_max_min_median[0])\n",
    "            watch_ad_mean.append(temp_sum_mean_var_max_min_median[1])\n",
    "            watch_ad_var.append(temp_sum_mean_var_max_min_median[2])\n",
    "            watch_ad_max.append(temp_sum_mean_var_max_min_median[3])\n",
    "            watch_ad_median.append(temp_sum_mean_var_max_min_median[4])\n",
    "            audience_targeting_type_nums_dict[audience_targeting_str]=temp_sum_mean_var_max_min_median\n",
    "            print(temp_sum_mean_var_max_min_median)\n",
    "    df_train_date['audience_targeting']=df_train_date['audience_targeting'].apply(lambda x: '|'.join(x))\n",
    "    #把人群定向列转换为原始的字符串，数据格式统一\n",
    "    \n",
    "    df_users_watch_ad=pd.DataFrame({\"users_watch_ad_sum\":watch_ad_sum,\"users_watch_ad_mean\":watch_ad_mean,\"users_watch_ad_var\":watch_ad_var,\n",
    "                 \"users_watch_ad_max\":watch_ad_max,\"users_watch_ad_median\":watch_ad_median})\n",
    "    df_users_watch_ad.fillna(0,inplace=True)\n",
    "    df_train_date=pd.concat([df_train_date,df_users_watch_ad],axis=1)\n",
    "\n",
    "    with open('audience_targeting_type_nums_dict.json','w') as outfile:#写入json文件，保存字典，方便下一个训练集提取特征使用\n",
    "        json.dump(audience_targeting_type_nums_dict,outfile,ensure_ascii=False)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "    df_train_date.to_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_feature2phase_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_phase2(date_train_extract,date_before_day_train_extract,date_before_two_day_train_extract,user_data,totalExposureLog):\n",
    "    df_train_date=history_exposure_times_mean(date_train_extract)\n",
    "    df_train_date=audience_target_item_nums(df_train_date)\n",
    "    df_train_date=day_before_exposure_times(df_train_date,date_before_day_train_extract,date_before_two_day_train_extract,totalExposureLog)\n",
    "    user_id_watch_ad_nums_sum_mean_var_max_min_median(df_train_date,user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load total exposure log\n",
      "load user data\n",
      "load data finished\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1396718 entries, 0 to 1396717\n",
      "Data columns (total 11 columns):\n",
      "user_id               1396718 non-null int64\n",
      "age                   1396718 non-null int64\n",
      "gender                1396718 non-null int64\n",
      "area                  1396718 non-null object\n",
      "status                1396718 non-null object\n",
      "education             1396718 non-null int64\n",
      "consuption_ability    1396718 non-null int64\n",
      "device                1396718 non-null int64\n",
      "work                  1396718 non-null object\n",
      "connection_type       1396718 non-null int64\n",
      "behavior              1396718 non-null object\n",
      "dtypes: int64(7), object(4)\n",
      "memory usage: 117.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1396718 entries, 0 to 1396717\n",
      "Data columns (total 12 columns):\n",
      "user_id                      1396718 non-null int64\n",
      "age                          1396718 non-null int64\n",
      "gender                       1396718 non-null int64\n",
      "area                         1396718 non-null object\n",
      "status                       1396718 non-null object\n",
      "education                    1396718 non-null int64\n",
      "consuption_ability           1396718 non-null int64\n",
      "device                       1396718 non-null int64\n",
      "work                         1396718 non-null object\n",
      "connection_type              1396718 non-null int64\n",
      "behavior                     1396718 non-null object\n",
      "user_id_watch_all_ad_nums    1396718 non-null float64\n",
      "dtypes: float64(1), int64(7), object(4)\n",
      "memory usage: 138.5+ MB\n",
      "None\n",
      "user_id history exposure times compute finished\n"
     ]
    }
   ],
   "source": [
    "date_train_extract_list=['0319']\n",
    "date_before_day_train_extract_list=['0318']\n",
    "date_before_two_day_train_extract_list=['0317']\n",
    "\n",
    "user_data,totalExposureLog=user_data_user_id_watch_all_ad_nums_ready()\n",
    "for date_train_extract,date_before_day_train_extract,date_before_two_day_train_extract in zip(date_train_extract_list,date_before_day_train_extract_list,date_before_two_day_train_extract_list):\n",
    "    print('2019',date_train_extract,date_before_day_train_extract,date_before_two_day_train_extract)\n",
    "    get_feature_phase2(date_train_extract,date_before_day_train_extract,date_before_two_day_train_extract,user_data,totalExposureLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train_extract_list=['0318','3017','0316','0315','0314','0313','3012','0311','0310','0309','0308','3007','0306','0305','0304','0303']\n",
    "date_before_day_train_extract_list=['0317','0316','0315','0314','0313','3012','0311','0310','0309','0308','3007','0306','0305','0304','0303','0302']\n",
    "date_before_two_day_train_extract_list=['0316','0315','0314','0313','3012','0311','0310','0309','0308','3007','0306','0305','0304','0303','0302','0301']\n",
    "\n",
    "# user_data,totalExposureLog=user_data_user_id_watch_all_ad_nums_ready()\n",
    "for date_train_extract,date_before_day_train_extract,date_before_two_day_train_extract in zip(date_train_extract_list,date_before_day_train_extract_list,date_before_two_day_train_extract_list):\n",
    "    print('2019',date_train_extract,date_before_day_train_extract,date_before_two_day_train_extract)\n",
    "    get_feature_phase2(date_train_extract,date_before_day_train_extract,date_before_two_day_train_extract,user_data,totalExposureLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train_extract='0318'\n",
    "date_before_day_train_extract='0317'\n",
    "date_before_two_day_train_extract='0316'\n",
    "df_train_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_feature1phase_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_static_feature=pd.read_csv(\"../Data/A_preliminary/testA/ad_static_feature.out\",header=None,sep='\\t',\n",
    "                             names=['ad_id','create_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size',\n",
    "                             ])\n",
    "df_train_date.rename(columns={'create_time':'start_time'},inplace=True)\n",
    "df_train_date=df_train_date.merge(ad_static_feature[['ad_id','create_time']],on='ad_id',how='inner')\n",
    "df_train_date['have_create_seconds']=df_train_date['end_time']-df_train_date['create_time']\n",
    "df_train_date['have_create_days']=df_train_date['have_create_seconds']//86400+1\n",
    "df_train_date['history_exposure_times_mean']=df_train_date['ad_id_history_exposure_times']/df_train_date['have_create_days']\n",
    "\n",
    "del ad_static_feature\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_date['history_exposure_times_mean'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_date['audience_targeting']=df_train_date['audience_targeting'].apply(self_split_by_long)\n",
    "audience_target_dict={'age':[],'gender':[],'area':[],'status':[],'education':[],'consuption_ability':[],\n",
    "                          'device':[],'work':[],'connection_type':[],'behavior':[]}\n",
    "for sample_index,audience_targeting_list in zip(df_train_date.index,df_train_date['audience_targeting']):\n",
    "    if audience_targeting_list[0]=='all':#定向为全体人群时\n",
    "        for key in audience_target_dict.keys():\n",
    "            audience_target_dict[key].append(0)\n",
    "        continue\n",
    "    target_type_content_dict={}\n",
    "    for target_type_content in audience_targeting_list:\n",
    "        target_type_content_list=target_type_content.split(':')\n",
    "        target_type_content_dict[target_type_content_list[0]]=target_type_content_list[1].split(',')\n",
    "        #如{'age':[787,753,601,202,229,333,741,819,479,608,433,394], 'gender':2}所有的定向要求变成dict，方便查询\n",
    "    for key in audience_target_dict.keys():\n",
    "        audience_target_dict[key].append(len(target_type_content_dict.get(key,[])))\n",
    "df_audience_target=pd.DataFrame(audience_target_dict)\n",
    "df_audience_target.rename(columns={'age':'age_item_nums','gender':'gender_item_nums','area':'area_item_nums','status':'status_item_nums',\n",
    "         'education':'education_item_nums','consuption_ability':'consuption_ability_item_nums','device':'device_item_nums',\n",
    "        'work':'work_item_nums','connection_type':'connection_type_item_nums','behavior':'behavior_item_nums'},inplace=True)\n",
    "df_train_date=pd.concat([df_train_date,df_audience_target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_date[['age_item_nums','gender_item_nums','area_item_nums','status_item_nums','education_item_nums','consuption_ability_item_nums',\n",
    "               'device_item_nums','work_item_nums','connection_type_item_nums','behavior_item_nums']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('load total exposure log')\n",
    "totalExposureLog=pd.read_csv(\"../Data/A_preliminary/testA/totalExposureLog.out\",header=None,sep='\\t',\n",
    "                                 names=['request_id','ad_request_time','ad_position','user_id','exposure_ad_id','exposure_ad_size','bid','pctr',\n",
    "                                        'quality_ecpm','total_ecpm'])\n",
    "train_date_train_extract_exposurelog=totalExposureLog[\n",
    "        (totalExposureLog['ad_request_time']>datetime2SecondsFrom1970_s('2019'+date_before_two_day_train_extract+'235959')) & \n",
    "        (totalExposureLog['ad_request_time']<=datetime2SecondsFrom1970_s('2019'+date_before_day_train_extract+'235959'))]\n",
    "train_date_train_extract_exposurelog.index=range(train_date_train_extract_exposurelog.shape[0])\n",
    "    #训练集提取日期 date_train_extract  ！！！前一天的！！！ 曝光日志找出来。\n",
    "df_ad_id_beforeday_exposure_times=train_date_train_extract_exposurelog.groupby('exposure_ad_id').aggregate('size').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad_id_beforeday_exposure_times=train_date_train_extract_exposurelog.groupby('exposure_ad_id')['user_id'].aggregate(['size']).reset_index()\n",
    "df_ad_id_beforeday_exposure_times.rename(columns={'size':'day_before_exposure_times'},inplace=True)\n",
    "df_train_date=df_train_date.merge(df_ad_id_beforeday_exposure_times,on='exposure_ad_id',how='left')\n",
    "df_train_date.fillna(0,inplace=True)\n",
    "df_user_id_watch_ad_nums=totalExposureLog.groupby('user_id')['request_id'].aggregate(['size']).reset_index()\n",
    "df_user_id_watch_ad_nums.rename(columns={'size':'user_id_watch_all_ad_nums'},inplace=True)\n",
    "del totalExposureLog\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data=pd.read_csv(\"../Data/A_preliminary/testA/user_data\",header=None,sep='\\t',\n",
    "                          names=['user_id','age','gender','area','status','education','consuption_ability','device','work','connection_type','behavior'])\n",
    "print('load data finished')\n",
    "\n",
    "print(user_data.info())\n",
    "user_data=user_data.merge(df_user_id_watch_ad_nums,on='user_id',how='left')\n",
    "user_data.fillna(0,inplace=True)\n",
    "print(user_data.info())\n",
    "print('user_id history exposure times compute finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['area']=user_data['area'].apply(self_split_by_comma)\n",
    "user_data['status']=user_data['status'].apply(self_split_by_comma)\n",
    "user_data['work']=user_data['work'].apply(self_split_by_comma)\n",
    "user_data['behavior']=user_data['behavior'].apply(lambda x: self_split_by_comma(x)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_audience_watch_ad_sum_mean_var_max_min_median_list=[]\n",
    "all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].sum(),2))\n",
    "all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].mean(),2))\n",
    "all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].var(),2))\n",
    "all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].max(),2))\n",
    "all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].min(),2))\n",
    "all_audience_watch_ad_sum_mean_var_max_min_median_list.append(round(user_data['user_id_watch_all_ad_nums'].median(),2))\n",
    "print(all_audience_watch_ad_sum_mean_var_max_min_median_list)\n",
    "print('load audience_targeting_type_nums_dict.json file ...')\n",
    "#相同的定向人群不用再去user_data中一一比对，用一个字典存储，有大量重复定向人群\n",
    "f=open(\"audience_targeting_type_nums_dict.json\",\"r\")\n",
    "data=list()\n",
    "for line in f:\n",
    "    data.append(json.loads(line))\n",
    "f.close()\n",
    "audience_targeting_type_nums_dict=data[0]\n",
    "\n",
    "watch_ad_sum=[]\n",
    "watch_ad_mean=[]\n",
    "watch_ad_var=[]\n",
    "watch_ad_max=[]\n",
    "watch_ad_min=[]\n",
    "watch_ad_median=[]\n",
    "for sample_index,audience_targeting_list in zip(df_train_date.index,df_train_date['audience_targeting']):\n",
    "    print(sample_index)\n",
    "    if audience_targeting_list[0]=='all':#定向为全体人群时\n",
    "        watch_ad_sum.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[0])\n",
    "        watch_ad_mean.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[1])\n",
    "        watch_ad_var.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[2])\n",
    "        watch_ad_max.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[3])\n",
    "        watch_ad_min.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[4])\n",
    "        watch_ad_median.append(all_audience_watch_ad_sum_mean_var_max_min_median_list[5])\n",
    "        print(all_audience_watch_ad_sum_mean_var_max_min_median_list)\n",
    "        continue\n",
    "    audience_targeting_str='|'.join(audience_targeting_list)\n",
    "    if audience_targeting_str in audience_targeting_type_nums_dict:\n",
    "        #有定向要求相同的、不同出价的广告样本，以及同类型的定向人群相同的广告样本。不需要再去数一次，存入一个dict中，若相同直接载入\n",
    "        watch_ad_sum.append(audience_targeting_type_nums_dict[audience_targeting_str][0])\n",
    "        watch_ad_mean.append(audience_targeting_type_nums_dict[audience_targeting_str][1])\n",
    "        watch_ad_var.append(audience_targeting_type_nums_dict[audience_targeting_str][2])\n",
    "        watch_ad_max.append(audience_targeting_type_nums_dict[audience_targeting_str][3])\n",
    "        watch_ad_min.append(audience_targeting_type_nums_dict[audience_targeting_str][4])\n",
    "        watch_ad_median.append(audience_targeting_type_nums_dict[audience_targeting_str][5])\n",
    "        print(audience_targeting_type_nums_dict[audience_targeting_str])\n",
    "        continue\n",
    "    else:\n",
    "        target_type_content_dict={}\n",
    "        for target_type_content in audience_targeting_list:\n",
    "            target_type_content_list=target_type_content.split(':')\n",
    "            target_type_content_dict[target_type_content_list[0]]=target_type_content_list[1].split(',')\n",
    "            #如{'age':[787,753,601,202,229,333,741,819,479,608,433,394], 'gender':2}所有的定向要求变成dict，方便查询\n",
    "        user_data['check']=True#新的check列，符合要求为True，否则False\n",
    "        for target_check in target_type_content_dict.keys():\n",
    "            if target_check =='age':\n",
    "                temp_set=set(target_type_content_dict['age'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['age'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "            elif target_check =='gender':\n",
    "                temp_set=set(target_type_content_dict['gender'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['gender'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "            elif target_check =='education':\n",
    "                temp_set=set(target_type_content_dict['education'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['education'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "            elif target_check =='consuption_ability':\n",
    "                temp_set=set(target_type_content_dict['consuption_ability'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['consuption_ability'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "            elif target_check =='device':\n",
    "                temp_set=set(target_type_content_dict['device'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['device'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "            elif target_check =='connection_type':\n",
    "                temp_set=set(target_type_content_dict['connection_type'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['connection_type'].apply(lambda x:set([str(x)])&temp_set)!=set())\n",
    "            #以上字段,用户属性只能一个的，如最高教育程度等，按定向要求的分组互相取并集获得check列\n",
    "            elif target_check=='area':\n",
    "                temp_set=set(target_type_content_dict['area'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['area'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "    #             print('area_check',sum(user_data['area_check']))\n",
    "            elif target_check=='status':\n",
    "                temp_set=set(target_type_content_dict['status'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['status'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "    #             print('status_check',sum(user_data['status_check']))\n",
    "            elif target_check=='work':\n",
    "                temp_set=set(target_type_content_dict['work'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['work'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "            elif target_check=='behavior':\n",
    "                temp_set=set(target_type_content_dict['behavior'])\n",
    "                user_data['check']=(user_data['check'])&(user_data['behavior'].apply(lambda x:set(x)&temp_set)!=set())\n",
    "            #这部分字段属于 用户属性可以有多个，同时定向要求可以有多个，将每项两部分作为set取交，交集不为空即符合check，=1\n",
    "        temp_sum_mean_var_max_min_median=[]\n",
    "        temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].sum(),2))\n",
    "        temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].mean(),2))\n",
    "        temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].var(),2))\n",
    "        temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].max(),2))\n",
    "        temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].min(),2))\n",
    "        temp_sum_mean_var_max_min_median.append(round(user_data['user_id_watch_all_ad_nums'][user_data['check']==True].median(),2))\n",
    "        \n",
    "        watch_ad_sum.append(temp_sum_mean_var_max_min_median[0])\n",
    "        watch_ad_mean.append(temp_sum_mean_var_max_min_median[1])\n",
    "        watch_ad_var.append(temp_sum_mean_var_max_min_median[2])\n",
    "        watch_ad_max.append(temp_sum_mean_var_max_min_median[3])\n",
    "        watch_ad_min.append(temp_sum_mean_var_max_min_median[4])\n",
    "        watch_ad_median.append(temp_sum_mean_var_max_min_median[5])\n",
    "        audience_targeting_type_nums_dict[audience_targeting_str]=temp_sum_mean_var_max_min_median\n",
    "        print(temp_sum_mean_var_max_min_median)\n",
    "df_train_date['audience_targeting']=df_train_date['audience_targeting'].apply(lambda x: '|'.join(x))\n",
    "#把人群定向列转换为原始的字符串，数据格式统一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_watch_ad=pd.DataFrame({\"users_watch_ad_sum\":watch_ad_sum,\"users_watch_ad_mean\":watch_ad_mean,\"users_watch_ad_var\":watch_ad_var,\n",
    "             \"users_watch_ad_max\":watch_ad_max,\"users_watch_ad_median\":watch_ad_median})\n",
    "df_users_watch_ad.fillna(0,inplace=True)\n",
    "df_train_date=pd.concat([df_train_date,df_users_watch_ad],axis=1)\n",
    "\n",
    "with open('audience_targeting_type_nums_dict.json','w') as outfile:#写入json文件，保存字典，方便下一个训练集提取特征使用\n",
    "    json.dump(audience_targeting_type_nums_dict,outfile,ensure_ascii=False)\n",
    "    outfile.write('\\n')\n",
    "\n",
    "df_train_date.to_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_feature2phase_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_index=0\n",
    "for index in range(5,len(df_train_date.columns)+5,5):\n",
    "    print(list(df_train_date.columns)[last_index:index])\n",
    "    last_index=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_date.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_date['have_create_seconds'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data=pd.read_csv(\"../Data/A_preliminary/testA/user_data\",header=None,sep='\\t',\n",
    "                          names=['user_id','age','gender','area','status','education','consuption_ability',\n",
    "                                 'device','work','connection_type','behavior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_date=pd.concat([df_train_date,df_audience_target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.toarray().shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data=pd.read_csv(\"../Data/A_preliminary/testA/user_data\",header=None,sep='\\t',\n",
    "                          names=['user_id','age','gender','area','status','education','consuption_ability','device','work','connection_type','behavior'])\n",
    "user_data.fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = user_data['behavior'].apply(lambda x:str(x))\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "# print(X.toarray())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(user_data['behavior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extract Phase1\n",
    "## 1 各种id，分组后bid,pctr,quality_ecpm,total_ecpm的均值方差情况，以及历史总曝光量\n",
    "    \n",
    "   其中有没被曝光过的ad_id,account_id等以有曝光的中位数进行填充。\n",
    "   \n",
    "   **中位数分为两种情况：**（1）简单的，使用3月19日前所有的曝光数据，统一提取各个mean,var,并使用该数据进行填充训练集。“考虑模型泛化性”\n",
    "                  （2）复杂的，按训练集每次提取的情况，分别提取如3月15日、3月13日前的曝光数据的各个mean，var,填充数据集。“强拟合性”\n",
    "## 2 ad_size one hot vectorization\n",
    "   ad_size 总的类别不超过20，且原本就属于类别变量，其连续值不具有数据含义。\n",
    "## 3 weekday\n",
    "   不同的周时间具有不同的曝光量级，有效的特征。\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_phase1(date_train_extract,week_day):\n",
    "    id_type_meanvar_value_dict={'ad_id_bid_mean': 94.72470632815461, 'ad_id_bid_var': 2479.927053140097, 'ad_id_pctr_mean': 7.456589060308556, 'ad_id_pctr_var': 34.23330065649351, 'ad_id_quality_ecpm_mean': 147.76, 'ad_id_quality_ecpm_var': 14000.430519787134, 'ad_id_total_ecpm_mean': 1077.9321328671329, 'ad_id_total_ecpm_var': 842624.7463645847, 'ad_id_history_exposure_times': 19.0, 'account_id_bid_mean': 100.0, 'account_id_bid_var': 1038.6994609164421, 'account_id_pctr_mean': 5.983306693815211, 'account_id_pctr_var': 44.829312856614244, 'account_id_quality_ecpm_mean': 118.35692427790775, 'account_id_quality_ecpm_var': 18034.33437609951, 'account_id_total_ecpm_mean': 723.3500251926495, 'account_id_total_ecpm_var': 697526.679498976, 'account_id_history_exposure_times': 100.0, 'commodity_id_bid_mean': 100.0, 'commodity_id_bid_var': 302.5615384615385, 'commodity_id_pctr_mean': 4.063576923076923, 'commodity_id_pctr_var': 20.48011833986928, 'commodity_id_quality_ecpm_mean': 80.2, 'commodity_id_quality_ecpm_var': 8145.380440080895, 'commodity_id_total_ecpm_mean': 473.3102156862746, 'commodity_id_total_ecpm_var': 271345.84545676154, 'commodity_id_history_exposure_times': 28.0, 'commodity_type_bid_mean': 222.34001000795175, 'commodity_type_bid_var': 16547613.501672428, 'commodity_type_pctr_mean': 16.06287553616584, 'commodity_type_pctr_var': 545.5364423130397, 'commodity_type_quality_ecpm_mean': 389.4260059297535, 'commodity_type_quality_ecpm_var': 1394784.0457270064, 'commodity_type_total_ecpm_mean': 1422.224997028004, 'commodity_type_total_ecpm_var': 7992557.585475998, 'commodity_type_history_exposure_times': 1802431.5, 'trades_id_bid_mean': 118.37847514324936, 'trades_id_bid_var': 44325.1534180594, 'trades_id_pctr_mean': 11.876398353191423, 'trades_id_pctr_var': 362.578142419821, 'trades_id_quality_ecpm_mean': 241.28115127897505, 'trades_id_quality_ecpm_var': 162692.87596998204, 'trades_id_total_ecpm_mean': 1450.9731769679152, 'trades_id_total_ecpm_var': 6590413.504289803, 'trades_id_history_exposure_times': 32880.0}\n",
    "    print('load exposure data\\n......')\n",
    "    df_totalExposureLog=pd.read_csv(\"../Data/A_preliminary/testA/totalExposureLog.out\",header=None,sep='\\t',\n",
    "                                 names=['request_id','ad_request_time','ad_position','user_id','exposure_ad_id','exposure_ad_size','bid','pctr',\n",
    "                                        'quality_ecpm','total_ecpm'])\n",
    "    df_totalExposureLog=df_totalExposureLog[df_totalExposureLog['ad_request_time']<=datetime2SecondsFrom1970_s('2019'+date_train_extract+'235959')]\n",
    "    print('load train source data')\n",
    "    df_train_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_train.csv')\n",
    "    df_train_date['ad_trades_id']=df_train_date['ad_trades_id'].apply(lambda x:int(str(x).split(',')[0]))\n",
    "    \n",
    "    print('exposurelog nums:',df_totalExposureLog.shape,'train_set nums:',df_train_date.shape)\n",
    "    print('after ad_id merge:',\"biger than 0:\",df_train_date[df_train_date['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",df_train_date[df_train_date['exposure_times']<=0].shape)\n",
    "    print('load data finished')\n",
    "    print('ad_id group bid..pctr mean var start')\n",
    "    #ad_id\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['exposure_ad_id'])['bid','pctr','quality_ecpm'\n",
    "                                                                                     ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['exposure_ad_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'ad_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['ad_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['ad_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['ad_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['ad_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['ad_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['ad_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['ad_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['ad_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_adid_meanvar=pd.merge(df_train_date,df_attribute_mean_var,left_on='ad_id',right_on='exposure_ad_id',how='left')\n",
    "    print('after ad_id merge:',\"biger than 0:\",df_train_set_date_feature_adid_meanvar[df_train_set_date_feature_adid_meanvar['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",df_train_set_date_feature_adid_meanvar[df_train_set_date_feature_adid_meanvar['exposure_times']<=0].shape)\n",
    "    df_train_set_date_feature_adid_meanvar.fillna(-8,inplace=True)\n",
    "    \n",
    "    print('ad_id mean ==-8 nums:')\n",
    "    print(df_train_set_date_feature_adid_meanvar[df_train_set_date_feature_adid_meanvar['ad_id_bid_mean']<0].shape)\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_bid_mean'][df_train_set_date_feature_adid_meanvar['ad_id_bid_mean']<0]=id_type_meanvar_value_dict['ad_id_bid_mean']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_bid_var'][df_train_set_date_feature_adid_meanvar['ad_id_bid_var']<0]=id_type_meanvar_value_dict['ad_id_bid_var']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_pctr_mean'][df_train_set_date_feature_adid_meanvar['ad_id_pctr_mean']<0]=id_type_meanvar_value_dict['ad_id_pctr_mean']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_pctr_var'][df_train_set_date_feature_adid_meanvar['ad_id_pctr_var']<0]=id_type_meanvar_value_dict['ad_id_pctr_var']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_mean'][df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_mean']<0]=id_type_meanvar_value_dict['ad_id_quality_ecpm_mean']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_var'][df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_var']<0]=id_type_meanvar_value_dict['ad_id_quality_ecpm_var']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_mean'][df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_mean']<0]=id_type_meanvar_value_dict['ad_id_total_ecpm_mean']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_var'][df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_var']<0]=id_type_meanvar_value_dict['ad_id_total_ecpm_var']\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_history_exposure_times'][df_train_set_date_feature_adid_meanvar['ad_id_history_exposure_times']<0]=id_type_meanvar_value_dict['ad_id_history_exposure_times']\n",
    "    \n",
    "    print('load static_feature data, append some static info like account id to exposurelog before the date that trainset extracted')\n",
    "    gc.collect()\n",
    "    ad_static_feature=pd.read_csv(\"../Data/A_preliminary/testA/ad_static_feature.out\",header=None,sep='\\t',\n",
    "                                 names=['ad_id','create_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size',\n",
    "                                 ])\n",
    "    df_temp=ad_static_feature[['ad_id','ad_account_id','commodity_id','commodity_type','ad_trades_id']]\n",
    "    df_totalExposureLog=pd.merge(df_totalExposureLog,df_temp,left_on='exposure_ad_id',right_on='ad_id',how='left')\n",
    "    del df_temp\n",
    "    gc.collect()\n",
    "    \n",
    "    print('account_id group bid..pctr mean var start')\n",
    "    #account_id\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['ad_account_id'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['ad_account_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'account_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['account_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['account_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['account_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['account_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['account_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['account_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['account_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['account_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='ad_account_id',how='left')\n",
    "    df_train_set_date_feature_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "    print('after account_id merge:',\"biger than 0:\",df_train_set_date_feature_accountid_adid_meanvar[df_train_set_date_feature_accountid_adid_meanvar['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",df_train_set_date_feature_accountid_adid_meanvar[df_train_set_date_feature_accountid_adid_meanvar['exposure_times']<=0].shape)\n",
    "    print('account_id mean ==-8 nums:')\n",
    "    print(df_train_set_date_feature_accountid_adid_meanvar['ad_account_id'][df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_mean']<0].shape)\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_bid_mean']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_bid_var']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_pctr_mean']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_pctr_var']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_quality_ecpm_mean']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_quality_ecpm_var']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_total_ecpm_mean']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['account_id_total_ecpm_var']\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_history_exposure_times'][df_train_set_date_feature_accountid_adid_meanvar['account_id_history_exposure_times']<0\n",
    "                                               ]=id_type_meanvar_value_dict['account_id_history_exposure_times']\n",
    "    \n",
    "    gc.collect()\n",
    "    print('commodity_id group bid..pctr mean var start')\n",
    "    # 'commodity_id'\n",
    "    df_totalExposureLog.fillna(-2,inplace=True)\n",
    "    df_totalExposureLog['commodity_id']=df_totalExposureLog['commodity_id'].apply(lambda x:int(str(x).split(',')[0]))\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['commodity_id'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['commodity_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'commodity_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['commodity_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['commodity_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['commodity_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['commodity_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['commodity_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['commodity_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_accountid_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='commodity_id',how='left')\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_bid_mean']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_bid_var']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_pctr_mean']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_pctr_var']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_quality_ecpm_mean']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_quality_ecpm_var']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_total_ecpm_mean']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_id_total_ecpm_var']\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_history_exposure_times'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_history_exposure_times']<0\n",
    "                                               ]=id_type_meanvar_value_dict['commodity_id_history_exposure_times']\n",
    "    \n",
    "    print('commodity_type group bid..pctr mean var start')\n",
    "    #'commodity_type'\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['commodity_type'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['commodity_type'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'commodity_type_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['commodity_type_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['commodity_type_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['commodity_type_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['commodity_type_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['commodity_type_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_type_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['commodity_type_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_type_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_commodityid_accountid_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='commodity_type',how='left')\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_bid_mean']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_bid_var']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_pctr_mean']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_pctr_var']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_quality_ecpm_mean']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_quality_ecpm_var']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_total_ecpm_mean']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['commodity_type_total_ecpm_var']\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_history_exposure_times'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_history_exposure_times']<0\n",
    "                                               ]=id_type_meanvar_value_dict['commodity_type_history_exposure_times']\n",
    "    \n",
    "    print('ad_trades_id group bid..pctr mean var start')\n",
    "    #'ad_trades_id'\n",
    "    df_totalExposureLog['ad_trades_id']=df_totalExposureLog['ad_trades_id'].apply(lambda x:int(str(x).split(',')[0]))\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['ad_trades_id'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['ad_trades_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'trades_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['trades_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['trades_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['trades_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['trades_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['trades_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['trades_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['trades_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['trades_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='ad_trades_id',how='left')\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_bid_mean']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_bid_var']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_pctr_mean']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_pctr_var']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_quality_ecpm_mean']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_quality_ecpm_var']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_mean']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_total_ecpm_mean']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_var']<0\n",
    "                                                   ]=id_type_meanvar_value_dict['trades_id_total_ecpm_var']\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_history_exposure_times'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_history_exposure_times']<0\n",
    "                                               ]=id_type_meanvar_value_dict['trades_id_history_exposure_times']\n",
    "    \n",
    "    print('week day')\n",
    "    #weekday\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['week_day']=week_day\n",
    "    print('ad_size one hot get dummies')\n",
    "    #ad_size\n",
    "    df_ad_size_onehot=pd.get_dummies(df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['ad_size'])\n",
    "    rename_dict={}\n",
    "    for ad_size_name in df_ad_size_onehot.columns:\n",
    "        rename_dict[ad_size_name]='ad_size_'+str(ad_size_name)\n",
    "    df_ad_size_onehot.rename(columns=rename_dict,inplace=True)\n",
    "    df_train_set_date_feature_adsize_tradesid_commoditytype_commodityid_accountid_adid_meanvar=pd.concat([df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar,df_ad_size_onehot],axis=1)\n",
    "\n",
    "    print('write to persistent disk')\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar.to_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_feature1phase_train.csv',index=False)\n",
    "    print('feature phrse 1 train finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# date_train_extract_list=['0308','0307','0306','0305','0309','0310','0311','0312','0313','0314','0315','0316','0317','0318','0319']\n",
    "# week_day_list=[4,3,2,1,6,0,1,2,3,4,5,6,0,1,2]\n",
    "date_train_extract_list=['0304','0303',]\n",
    "week_day_list=[0,6]\n",
    "for date_train_extract,week_day in zip(date_train_extract_list,week_day_list):\n",
    "    print('The date train set extract :','\\n------------------\\n2019 -',date_train_extract,'\\n------------------')\n",
    "    get_feature_phase1(date_train_extract,week_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_phase1_complex_median(date_train_extract,week_day):\n",
    "    print('load exposure data\\n......')\n",
    "    df_totalExposureLog=pd.read_csv(\"../Data/A_preliminary/testA/totalExposureLog.out\",header=None,sep='\\t',\n",
    "                                 names=['request_id','ad_request_time','ad_position','user_id','exposure_ad_id','exposure_ad_size','bid','pctr',\n",
    "                                        'quality_ecpm','total_ecpm'])\n",
    "    df_totalExposureLog=df_totalExposureLog[df_totalExposureLog['ad_request_time']<=datetime2SecondsFrom1970_s('2019'+date_train_extract+'235959')]\n",
    "    print('load train source data')\n",
    "    df_train_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_train.csv')\n",
    "    df_train_date['ad_trades_id']=df_train_date['ad_trades_id'].apply(lambda x:int(str(x).split(',')[0]))\n",
    "    \n",
    "    print('exposurelog nums:',df_totalExposureLog.shape,'train_set nums:',df_train_date.shape)\n",
    "    print('after ad_id merge:',\"biger than 0:\",df_train_date[df_train_date['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",df_train_date[df_train_date['exposure_times']<=0].shape)\n",
    "    print('load data finished')\n",
    "    print('ad_id group bid..pctr mean var start')\n",
    "    #ad_id\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['exposure_ad_id'])['bid','pctr','quality_ecpm'\n",
    "                                                                                     ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['exposure_ad_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'ad_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['ad_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['ad_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['ad_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['ad_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['ad_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['ad_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['ad_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['ad_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_adid_meanvar=pd.merge(df_train_date,df_attribute_mean_var,left_on='ad_id',right_on='exposure_ad_id',how='left')\n",
    "    print('after ad_id merge:',\"biger than 0:\",df_train_set_date_feature_adid_meanvar[df_train_set_date_feature_adid_meanvar['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",df_train_set_date_feature_adid_meanvar[df_train_set_date_feature_adid_meanvar['exposure_times']<=0].shape)\n",
    "    df_train_set_date_feature_adid_meanvar.fillna(-8,inplace=True)\n",
    "    \n",
    "    print('ad_id mean ==-8 nums:')\n",
    "    print(df_train_set_date_feature_adid_meanvar[df_train_set_date_feature_adid_meanvar['ad_id_bid_mean']<0].shape)\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_bid_mean'][df_train_set_date_feature_adid_meanvar['ad_id_bid_mean']<0]=df_attribute_mean_var['ad_id_bid_mean'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_bid_var'][df_train_set_date_feature_adid_meanvar['ad_id_bid_var']<0]=df_attribute_mean_var['ad_id_bid_var'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_pctr_mean'][df_train_set_date_feature_adid_meanvar['ad_id_pctr_mean']<0]=df_attribute_mean_var['ad_id_pctr_mean'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_pctr_var'][df_train_set_date_feature_adid_meanvar['ad_id_pctr_var']<0]=df_attribute_mean_var['ad_id_pctr_var'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_mean'][df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_mean']<0]=df_attribute_mean_var['ad_id_quality_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_var'][df_train_set_date_feature_adid_meanvar['ad_id_quality_ecpm_var']<0]=df_attribute_mean_var['ad_id_quality_ecpm_var'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_mean'][df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_mean']<0]=df_attribute_mean_var['ad_id_total_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_var'][df_train_set_date_feature_adid_meanvar['ad_id_total_ecpm_var']<0]=df_attribute_mean_var['ad_id_total_ecpm_var'].median()\n",
    "    df_train_set_date_feature_adid_meanvar['ad_id_history_exposure_times'][df_train_set_date_feature_adid_meanvar['ad_id_history_exposure_times']<0]=df_attribute_mean_var['ad_id_history_exposure_times'].median()\n",
    "    \n",
    "    print('load static_feature data, append some static info like account id to exposurelog before the date that trainset extracted')\n",
    "    gc.collect()\n",
    "    ad_static_feature=pd.read_csv(\"../Data/A_preliminary/testA/ad_static_feature.out\",header=None,sep='\\t',\n",
    "                                 names=['ad_id','create_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size',\n",
    "                                 ])\n",
    "    df_temp=ad_static_feature[['ad_id','ad_account_id','commodity_id','commodity_type','ad_trades_id']]\n",
    "    df_totalExposureLog=pd.merge(df_totalExposureLog,df_temp,left_on='exposure_ad_id',right_on='ad_id',how='left')\n",
    "    del df_temp\n",
    "    gc.collect()\n",
    "    \n",
    "    print('account_id group bid..pctr mean var start')\n",
    "    #account_id\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['ad_account_id'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['ad_account_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'account_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['account_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['account_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['account_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['account_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['account_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['account_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['account_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['account_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='ad_account_id',how='left')\n",
    "    df_train_set_date_feature_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "    print('after account_id merge:',\"biger than 0:\",df_train_set_date_feature_accountid_adid_meanvar[df_train_set_date_feature_accountid_adid_meanvar['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",df_train_set_date_feature_accountid_adid_meanvar[df_train_set_date_feature_accountid_adid_meanvar['exposure_times']<=0].shape)\n",
    "    print('account_id mean ==-8 nums:')\n",
    "    print(df_train_set_date_feature_accountid_adid_meanvar['ad_account_id'][df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_mean']<0].shape)\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_bid_mean'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_bid_var']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_bid_var'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_pctr_mean'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_pctr_var']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_pctr_var'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_quality_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_quality_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_quality_ecpm_var'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_mean'][df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_total_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_var'][df_train_set_date_feature_accountid_adid_meanvar['account_id_total_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['account_id_total_ecpm_var'].median()\n",
    "    df_train_set_date_feature_accountid_adid_meanvar['account_id_history_exposure_times'][df_train_set_date_feature_accountid_adid_meanvar['account_id_history_exposure_times']<0\n",
    "                                               ]=df_attribute_mean_var['account_id_history_exposure_times'].median()\n",
    "    \n",
    "    gc.collect()\n",
    "    print('commodity_id group bid..pctr mean var start')\n",
    "    # 'commodity_id'\n",
    "    df_totalExposureLog.fillna(-2,inplace=True)\n",
    "    df_totalExposureLog['commodity_id']=df_totalExposureLog['commodity_id'].apply(lambda x:int(str(x).split(',')[0]))\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['commodity_id'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['commodity_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'commodity_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['commodity_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['commodity_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['commodity_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['commodity_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['commodity_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['commodity_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_accountid_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='commodity_id',how='left')\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_bid_mean'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_bid_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_bid_var'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_pctr_mean'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_pctr_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_pctr_var'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_quality_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_quality_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_quality_ecpm_var'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_mean'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_total_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_var'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_total_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_id_total_ecpm_var'].median()\n",
    "    df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_history_exposure_times'][df_train_set_date_feature_commodityid_accountid_adid_meanvar['commodity_id_history_exposure_times']<0\n",
    "                                               ]=df_attribute_mean_var['commodity_id_history_exposure_times'].median()\n",
    "    \n",
    "    print('commodity_type group bid..pctr mean var start')\n",
    "    #'commodity_type'\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['commodity_type'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['commodity_type'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'commodity_type_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['commodity_type_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['commodity_type_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['commodity_type_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['commodity_type_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['commodity_type_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_type_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['commodity_type_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['commodity_type_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_commodityid_accountid_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='commodity_type',how='left')\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_bid_mean'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_bid_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_bid_var'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_pctr_mean'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_pctr_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_pctr_var'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_quality_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_quality_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_quality_ecpm_var'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_mean'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_total_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_var'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_total_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['commodity_type_total_ecpm_var'].median()\n",
    "    df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_history_exposure_times'][df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar['commodity_type_history_exposure_times']<0\n",
    "                                               ]=df_attribute_mean_var['commodity_type_history_exposure_times'].median()\n",
    "    \n",
    "    print('ad_trades_id group bid..pctr mean var start')\n",
    "    #'ad_trades_id'\n",
    "    df_totalExposureLog['ad_trades_id']=df_totalExposureLog['ad_trades_id'].apply(lambda x:int(str(x).split(',')[0]))\n",
    "    df_attribute_mean_var_temp=df_totalExposureLog.groupby(['ad_trades_id'])['bid','pctr','quality_ecpm'\n",
    "                                ,'total_ecpm'].aggregate(['mean','var']).reset_index()\n",
    "    df_attribute_mean_var=df_totalExposureLog.groupby(['ad_trades_id'])['bid'].size().reset_index()\n",
    "    df_attribute_mean_var.rename(columns={'bid':'trades_id_history_exposure_times'},inplace=True)\n",
    "\n",
    "    df_attribute_mean_var['trades_id_bid_mean']=df_attribute_mean_var_temp[('bid','mean')]\n",
    "    df_attribute_mean_var['trades_id_bid_var']=df_attribute_mean_var_temp[('bid','var')]\n",
    "    df_attribute_mean_var['trades_id_pctr_mean']=df_attribute_mean_var_temp[('pctr','mean')]\n",
    "    df_attribute_mean_var['trades_id_pctr_var']=df_attribute_mean_var_temp[('pctr','var')]\n",
    "    df_attribute_mean_var['trades_id_quality_ecpm_mean']=df_attribute_mean_var_temp[('quality_ecpm','mean')]\n",
    "    df_attribute_mean_var['trades_id_quality_ecpm_var']=df_attribute_mean_var_temp[('quality_ecpm','var')]\n",
    "    df_attribute_mean_var['trades_id_total_ecpm_mean']=df_attribute_mean_var_temp[('total_ecpm','mean')]\n",
    "    df_attribute_mean_var['trades_id_total_ecpm_var']=df_attribute_mean_var_temp[('total_ecpm','var')]\n",
    "    df_attribute_mean_var.fillna(-4,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar=pd.merge(df_train_set_date_feature_commoditytype_commodityid_accountid_adid_meanvar,\n",
    "                                                              df_attribute_mean_var,on='ad_trades_id',how='left')\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar.fillna(-8,inplace=True)\n",
    "\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_bid_mean'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_bid_var']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_bid_var'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_pctr_mean'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_pctr_var']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_pctr_var'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_quality_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_quality_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_quality_ecpm_var'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_mean'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_mean']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_total_ecpm_mean'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_var'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_total_ecpm_var']<0\n",
    "                                                   ]=df_attribute_mean_var['trades_id_total_ecpm_var'].median()\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_history_exposure_times'][df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['trades_id_history_exposure_times']<0\n",
    "                                               ]=df_attribute_mean_var['trades_id_history_exposure_times'].median()\n",
    "    \n",
    "    print('week day')\n",
    "    #weekday\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['week_day']=week_day\n",
    "    print('ad_size one hot get dummies')\n",
    "    #ad_size\n",
    "    df_ad_size_onehot=pd.get_dummies(df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar['ad_size'])\n",
    "    rename_dict={}\n",
    "    for ad_size_name in df_ad_size_onehot.columns:\n",
    "        rename_dict[ad_size_name]='ad_size_'+str(ad_size_name)\n",
    "    df_ad_size_onehot.rename(columns=rename_dict,inplace=True)\n",
    "    df_train_set_date_feature_adsize_tradesid_commoditytype_commodityid_accountid_adid_meanvar=pd.concat([df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar,df_ad_size_onehot],axis=1)\n",
    "\n",
    "    print('write to persistent disk')\n",
    "    df_train_set_date_feature_tradesid_commoditytype_commodityid_accountid_adid_meanvar.to_csv('../Data/A_preliminary_generate/Train/ad_sample_'+date_train_extract+'_feature1phase_complexMedian_train.csv',index=False)\n",
    "    print('feature phrse 1 train finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train_extract_list=['0309','0310','0311','0312','0313','0314','0315','0316','0317','0318','0319']\n",
    "week_day_list=[6,0,1,2,3,4,5,6,0,1,2]\n",
    "for date_train_extract,week_day in zip(date_train_extract_list,week_day_list):\n",
    "    print('The date train set extract :','\\n------------------\\n2019 -',date_train_extract,'\\n------------------')\n",
    "    get_feature_phase1_complex_median(date_train_extract,week_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2SecondsFrom1970(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y-%m-%d %H:%M:%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return secondsFrom1970\n",
    "\n",
    "def seconds2Datetime(seconds_from_1970):\n",
    "    timeArray = time.localtime(seconds_from_1970)#1970秒数\n",
    "    otherStyleTime = time.strftime(\"%Y-%m-%d %H:%M:%S\", timeArray)\n",
    "    datetime1=datetime.datetime.strptime(otherStyleTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return str(datetime1)\n",
    "def datetime2SecondsFrom1970_s(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y%m%d%H%M%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return int(secondsFrom1970)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestSet load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "ad_sample_test=pd.read_csv('../Data/A_preliminary_generate/Test/ad_sample_feature1phase_test.csv')\n",
    "\n",
    "ad_sample_test['have_create_seconds']=0\n",
    "\n",
    "ad_sample_test['have_create_seconds'][\n",
    "    ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190319235959')]=datetime2SecondsFrom1970_s('20190320235959')-ad_sample_test['create_time'][ad_sample_test['create_time']\n",
    "                                                                                                                                                 <=datetime2SecondsFrom1970_s('20190319235959')]\n",
    "#预测3月20日周三\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190319235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190320235959'))]=datetime2SecondsFrom1970_s('20190321235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190319235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190320235959'))]\n",
    "#3月21日周四\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190320235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190321235959'))]=datetime2SecondsFrom1970_s('20190322235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190320235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190321235959'))]\n",
    "#3月22日周五\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190321235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190322235959'))]=datetime2SecondsFrom1970_s('20190323235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190321235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190322235959'))]\n",
    "#3月23日周六\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190322235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190323235959'))]=datetime2SecondsFrom1970_s('20190324235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190322235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190323235959'))]\n",
    "#3月24日周日\n",
    "\n",
    "ad_sample_test['have_create_seconds'][(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190323235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190324235959'))]=datetime2SecondsFrom1970_s('20190325235959')-ad_sample_test['create_time'][\n",
    "(ad_sample_test['create_time']>datetime2SecondsFrom1970_s('20190323235959'))&\n",
    "(ad_sample_test['create_time']<=datetime2SecondsFrom1970_s('20190324235959'))]\n",
    "#3月25日周一\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 biger than 0: (5001, 109) equal 0: (12398, 109)\n",
      "4 biger than 0: (4729, 109) equal 0: (13799, 109)\n",
      "5 biger than 0: (4987, 109) equal 0: (11861, 109)\n",
      "6 biger than 0: (4453, 109) equal 0: (11701, 109)\n",
      "7 biger than 0: (4489, 109) equal 0: (10629, 109)\n",
      "8 biger than 0: (4785, 109) equal 0: (11009, 109)\n",
      "9 biger than 0: (4780, 109) equal 0: (9562, 109)\n",
      "10 biger than 0: (4759, 109) equal 0: (10244, 109)\n",
      "11 biger than 0: (4637, 109) equal 0: (10856, 109)\n",
      "12 biger than 0: (4763, 109) equal 0: (10364, 109)\n",
      "13 biger than 0: (4837, 109) equal 0: (10949, 109)\n",
      "14 biger than 0: (5090, 109) equal 0: (11247, 109)\n",
      "15 biger than 0: (5137, 109) equal 0: (12185, 109)\n",
      "16 biger than 0: (4257, 109) equal 0: (7132, 109)\n",
      "17 biger than 0: (4346, 109) equal 0: (7560, 109)\n",
      "18 biger than 0: (3511, 109) equal 0: (6561, 109)\n",
      "19 biger than 0: (4401, 109) equal 0: (8991, 109)\n"
     ]
    }
   ],
   "source": [
    "for day in range(3,20):\n",
    "    if day <10:\n",
    "        train_set_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+'030'+str(day)+'_feature1phase_train.csv')\n",
    "    else:\n",
    "        train_set_date=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_'+'03'+str(day)+'_feature1phase_train.csv')\n",
    "    print(day,\"biger than 0:\",train_set_date[train_set_date['exposure_times']>0].shape\n",
    "          ,\"equal 0:\",train_set_date[train_set_date['exposure_times']<=0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(valid_set_from_3_19['ad_id'])&set(train_set_3_03['ad_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_3_19[:2000][train_set_3_19['exposure_times']>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_set load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ad_static_feature=pd.read_csv(\"../Data/A_preliminary/testA/ad_static_feature.out\",header=None,sep='\\t',\n",
    "                             names=['ad_id','create_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size',\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_3_19=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0319_feature1phase_train.csv')\n",
    "valid_set_from_3_19=train_set_3_19[:2000]#设定验证集\n",
    "train_set_3_19=train_set_3_19[2000:]\n",
    "train_set_3_18=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0318_feature1phase_train.csv')\n",
    "train_set_3_17=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0317_feature1phase_train.csv')\n",
    "# train_set_3_17=train_set_3_17[train_set_3_17['exposure_times']>0]\n",
    "train_set_3_16=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0316_feature1phase_train.csv')\n",
    "# train_set_3_16=train_set_3_16[train_set_3_16['exposure_times']>0]\n",
    "train_set_3_15=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0315_feature1phase_train.csv')\n",
    "# train_set_3_15=train_set_3_15[train_set_3_15['exposure_times']>0]\n",
    "train_set_3_14=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0314_feature1phase_train.csv')\n",
    "# train_set_3_14=train_set_3_14[train_set_3_14['exposure_times']>0]\n",
    "train_set_3_13=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0313_feature1phase_train.csv')\n",
    "# train_set_3_13=train_set_3_13[train_set_3_13['exposure_times']>0]\n",
    "train_set_3_12=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0312_feature1phase_train.csv')\n",
    "# train_set_3_12=train_set_3_12[train_set_3_12['exposure_times']>0]\n",
    "train_set_3_11=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0311_feature1phase_train.csv')\n",
    "# train_set_3_11=train_set_3_11[train_set_3_11['exposure_times']>0]\n",
    "train_set_3_10=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0310_feature1phase_train.csv')\n",
    "# train_set_3_10=train_set_3_10[train_set_3_10['exposure_times']>0]\n",
    "train_set_3_09=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0309_feature1phase_train.csv')\n",
    "# train_set_3_09=train_set_3_09[train_set_3_09['exposure_times']>0]\n",
    "train_set_3_08=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0308_feature1phase_train.csv')\n",
    "train_set_3_07=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0307_feature1phase_train.csv')\n",
    "train_set_3_06=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0306_feature1phase_train.csv')\n",
    "train_set_3_05=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0305_feature1phase_train.csv')\n",
    "train_set_3_04=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0304_feature1phase_train.csv')\n",
    "train_set_3_03=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0303_feature1phase_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 236611 entries, 2000 to 18527\n",
      "Columns: 108 entries, ad_id to week_day\n",
      "dtypes: float64(46), int64(61), object(1)\n",
      "memory usage: 196.8+ MB\n",
      "train\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 236611 entries, 0 to 236610\n",
      "Columns: 110 entries, ad_id to have_create_seconds\n",
      "dtypes: float64(46), int64(63), object(1)\n",
      "memory usage: 200.4+ MB\n",
      "train\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 1999\n",
      "Columns: 110 entries, ad_id to have_create_seconds\n",
      "dtypes: float64(46), int64(63), object(1)\n",
      "memory usage: 1.7+ MB\n",
      "valid\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "train_set=pd.DataFrame([])\n",
    "train_set=pd.concat([train_set,train_set_3_19],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_18],axis=0)\n",
    "train_set['ad_trades_id']=train_set['ad_trades_id'].apply(lambda x: int(str(x).split(',')[0]))\n",
    "#3月18,19日两天有275条样本交易行业超过一个，但是test_sample中不存在这样的样本，直接取第一个\n",
    "train_set=pd.concat([train_set,train_set_3_17],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_16],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_15],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_14],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_13],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_12],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_11],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_10],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_09],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_08],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_07],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_06],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_05],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_04],axis=0)\n",
    "# train_set=pd.concat([train_set,train_set_3_03],axis=0)\n",
    "train_set.drop(columns='create_time',inplace=True)\n",
    "valid_set_from_3_19.drop(columns='create_time',inplace=True)\n",
    "print('train\\n',train_set.info())\n",
    "train_set=train_set.merge(ad_static_feature[['ad_id','create_time']],on='ad_id',how='inner')\n",
    "valid_set_from_3_19=valid_set_from_3_19.merge(ad_static_feature[['ad_id','create_time']],on='ad_id',how='inner')\n",
    "train_set['have_create_seconds']=train_set['end_time']-train_set['create_time']\n",
    "valid_set_from_3_19['have_create_seconds']=valid_set_from_3_19['end_time']-valid_set_from_3_19['create_time']\n",
    "print('train\\n',train_set.info())\n",
    "print('valid\\n',valid_set_from_3_19.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236611\n",
      "236611\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228871 entries, 0 to 228870\n",
      "Columns: 111 entries, index to have_create_seconds\n",
      "dtypes: float64(46), int64(64), object(1)\n",
      "memory usage: 193.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape[0])\n",
    "train_set.drop_duplicates(inplace=True)\n",
    "print(train_set.shape[0])#去重\n",
    "train_set=train_set[(train_set['hold_time']>10800)]#持续时间需要超过三个小时的样本\n",
    "# train_set=train_set[(train_set['audience_orientation_nums']>0)]#定向人群数量为0的是有问题的\n",
    "train_set.reset_index(inplace=True)\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation_set split  &  feature fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list=[\n",
    "# 'ad_id','audience_targeting','end_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size','hold_time',\n",
    "#  'create_time','sample_id', 'exposure_ad_id',\n",
    " 'bid','audience_orientation_nums','0000_0030','0030_0100','0100_0130','0130_0200','0200_0230','0230_0300','0300_0330',\n",
    "'0330_0400','0400_0430','0430_0500','0500_0530','0530_0600','0600_0630','0630_0700','0700_0730','0730_0800','0800_0830','0830_0900',\n",
    "'0900_0930','0930_1000','1000_1030','1030_1100','1100_1130','1130_1200','1200_1230','1230_1300','1300_1330','1330_1400','1400_1430','1430_1500',\n",
    "'1500_1530','1530_1600','1600_1630','1630_1700','1700_1730','1730_1800','1800_1830','1830_1900','1900_1930','1930_2000','2000_2030','2030_2100',\n",
    "'2100_2130','2130_2200','2200_2230','2230_2300','2300_2330','2330_2400',\n",
    "'ad_id_history_exposure_times','ad_id_bid_mean','ad_id_bid_var','ad_id_pctr_mean','ad_id_pctr_var','ad_id_quality_ecpm_mean',\n",
    "'ad_id_quality_ecpm_var','ad_id_total_ecpm_mean','ad_id_total_ecpm_var', \n",
    "'account_id_history_exposure_times','account_id_bid_mean','account_id_bid_var','account_id_pctr_mean','account_id_pctr_var',\n",
    "'account_id_quality_ecpm_mean','account_id_quality_ecpm_var','account_id_total_ecpm_mean','account_id_total_ecpm_var',\n",
    "'commodity_id_history_exposure_times','commodity_id_bid_mean','commodity_id_bid_var','commodity_id_pctr_mean','commodity_id_pctr_var',\n",
    "'commodity_id_quality_ecpm_mean','commodity_id_quality_ecpm_var','commodity_id_total_ecpm_mean','commodity_id_total_ecpm_var',\n",
    "'commodity_type_history_exposure_times','commodity_type_bid_mean','commodity_type_bid_var','commodity_type_pctr_mean',\n",
    "'commodity_type_pctr_var','commodity_type_quality_ecpm_mean','commodity_type_quality_ecpm_var','commodity_type_total_ecpm_mean',\n",
    "'commodity_type_total_ecpm_var',\n",
    "'trades_id_history_exposure_times','trades_id_bid_mean','trades_id_bid_var','trades_id_pctr_mean','trades_id_pctr_var',\n",
    "'trades_id_quality_ecpm_mean','trades_id_quality_ecpm_var','trades_id_total_ecpm_mean','trades_id_total_ecpm_var',\n",
    "'week_day','have_create_seconds']\n",
    "\n",
    "label=train_set['exposure_times']\n",
    "train=train_set[columns_list]\n",
    "test=ad_sample_test[columns_list]\n",
    "label_validtion=valid_set_from_3_19['exposure_times']\n",
    "validtion=valid_set_from_3_19[columns_list]\n",
    "\n",
    "label_valid_array=label_validtion.values\n",
    "validtion_array=validtion.values\n",
    "train_array=train.values\n",
    "label_array=label.values\n",
    "test_array=test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(valid_,label_valid_array):\n",
    "    temp_differ_abs=abs(valid_-label_valid_array)\n",
    "    temp_sum_mod_2=(valid_+label_valid_array)/2\n",
    "    \n",
    "    print(40*(1-(sum(temp_differ_abs/temp_sum_mod_2)/label_valid_array.shape[0]/2)))\n",
    "    return sum(temp_differ_abs/temp_sum_mod_2)/label_valid_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:92.6412\tvalid_data-rmse:56.1699\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:67.6752\tvalid_data-rmse:40.553\n",
      "[200]\ttrain-rmse:51.0796\tvalid_data-rmse:32.1364\n",
      "[300]\ttrain-rmse:39.6536\tvalid_data-rmse:27.9575\n",
      "[400]\ttrain-rmse:31.6801\tvalid_data-rmse:25.8701\n",
      "[500]\ttrain-rmse:26.0421\tvalid_data-rmse:24.9353\n",
      "[600]\ttrain-rmse:21.8858\tvalid_data-rmse:24.5847\n",
      "[700]\ttrain-rmse:18.7577\tvalid_data-rmse:24.3923\n",
      "[800]\ttrain-rmse:16.5461\tvalid_data-rmse:24.2824\n",
      "[900]\ttrain-rmse:14.8904\tvalid_data-rmse:24.2265\n",
      "[1000]\ttrain-rmse:13.6814\tvalid_data-rmse:24.1903\n",
      "[1100]\ttrain-rmse:12.8027\tvalid_data-rmse:24.1503\n",
      "[1200]\ttrain-rmse:12.1192\tvalid_data-rmse:24.1432\n",
      "[1300]\ttrain-rmse:11.5982\tvalid_data-rmse:24.1123\n",
      "[1400]\ttrain-rmse:11.2028\tvalid_data-rmse:24.1358\n",
      "Stopping. Best iteration:\n",
      "[1299]\ttrain-rmse:11.6031\tvalid_data-rmse:24.1101\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:89.3227\tvalid_data-rmse:92.0394\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:65.5601\tvalid_data-rmse:70.6638\n",
      "[200]\ttrain-rmse:49.197\tvalid_data-rmse:60.1155\n",
      "[300]\ttrain-rmse:37.9079\tvalid_data-rmse:56.5109\n",
      "[400]\ttrain-rmse:30.03\tvalid_data-rmse:56.4324\n",
      "[500]\ttrain-rmse:24.4087\tvalid_data-rmse:57.9235\n",
      "Stopping. Best iteration:\n",
      "[338]\ttrain-rmse:34.5806\tvalid_data-rmse:56.0982\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:84.2247\tvalid_data-rmse:128.277\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:61.2514\tvalid_data-rmse:110.091\n",
      "[200]\ttrain-rmse:46.2037\tvalid_data-rmse:99.7227\n",
      "[300]\ttrain-rmse:35.8678\tvalid_data-rmse:94.76\n",
      "[400]\ttrain-rmse:28.7184\tvalid_data-rmse:91.6539\n",
      "[500]\ttrain-rmse:23.8169\tvalid_data-rmse:89.6745\n",
      "[600]\ttrain-rmse:20.3313\tvalid_data-rmse:88.1857\n",
      "[700]\ttrain-rmse:17.7295\tvalid_data-rmse:86.3562\n",
      "[800]\ttrain-rmse:15.7881\tvalid_data-rmse:84.8891\n",
      "[900]\ttrain-rmse:14.3041\tvalid_data-rmse:83.9662\n",
      "[1000]\ttrain-rmse:13.2286\tvalid_data-rmse:83.1155\n",
      "[1100]\ttrain-rmse:12.4382\tvalid_data-rmse:82.3841\n",
      "[1200]\ttrain-rmse:11.8078\tvalid_data-rmse:81.7929\n",
      "[1300]\ttrain-rmse:11.3352\tvalid_data-rmse:81.5289\n",
      "[1400]\ttrain-rmse:10.9372\tvalid_data-rmse:81.1799\n",
      "[1500]\ttrain-rmse:10.6095\tvalid_data-rmse:80.9228\n",
      "[1600]\ttrain-rmse:10.3521\tvalid_data-rmse:80.6871\n",
      "[1700]\ttrain-rmse:10.1363\tvalid_data-rmse:80.6098\n",
      "[1800]\ttrain-rmse:9.94886\tvalid_data-rmse:80.535\n",
      "[1900]\ttrain-rmse:9.79754\tvalid_data-rmse:80.5211\n",
      "[2000]\ttrain-rmse:9.65442\tvalid_data-rmse:80.5146\n",
      "[2100]\ttrain-rmse:9.51999\tvalid_data-rmse:80.5214\n",
      "Stopping. Best iteration:\n",
      "[1957]\ttrain-rmse:9.72004\tvalid_data-rmse:80.4949\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:90.3309\tvalid_data-rmse:83.2509\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:65.7468\tvalid_data-rmse:68.7228\n",
      "[200]\ttrain-rmse:49.1889\tvalid_data-rmse:61.9099\n",
      "[300]\ttrain-rmse:37.8292\tvalid_data-rmse:58.5819\n",
      "[400]\ttrain-rmse:30.0777\tvalid_data-rmse:57.373\n",
      "[500]\ttrain-rmse:24.5836\tvalid_data-rmse:57.0402\n",
      "[600]\ttrain-rmse:20.5931\tvalid_data-rmse:57.0423\n",
      "[700]\ttrain-rmse:17.7231\tvalid_data-rmse:57.1975\n",
      "Stopping. Best iteration:\n",
      "[550]\ttrain-rmse:22.4208\tvalid_data-rmse:56.993\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:90.8049\tvalid_data-rmse:78.3079\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:66.4122\tvalid_data-rmse:61.0253\n",
      "[200]\ttrain-rmse:49.796\tvalid_data-rmse:50.5404\n",
      "[300]\ttrain-rmse:38.27\tvalid_data-rmse:44.0877\n",
      "[400]\ttrain-rmse:30.3812\tvalid_data-rmse:40.3799\n",
      "[500]\ttrain-rmse:24.947\tvalid_data-rmse:38.2509\n",
      "[600]\ttrain-rmse:20.906\tvalid_data-rmse:37.2067\n",
      "[700]\ttrain-rmse:17.9459\tvalid_data-rmse:36.5948\n",
      "[800]\ttrain-rmse:15.8199\tvalid_data-rmse:36.2922\n",
      "[900]\ttrain-rmse:14.2494\tvalid_data-rmse:36.1296\n",
      "[1000]\ttrain-rmse:13.1425\tvalid_data-rmse:36.0176\n",
      "[1100]\ttrain-rmse:12.3573\tvalid_data-rmse:35.9757\n",
      "[1200]\ttrain-rmse:11.7273\tvalid_data-rmse:35.9415\n",
      "[1300]\ttrain-rmse:11.2608\tvalid_data-rmse:35.8963\n",
      "[1400]\ttrain-rmse:10.9082\tvalid_data-rmse:35.8603\n",
      "[1500]\ttrain-rmse:10.623\tvalid_data-rmse:35.8028\n",
      "[1600]\ttrain-rmse:10.4078\tvalid_data-rmse:35.8074\n",
      "[1700]\ttrain-rmse:10.193\tvalid_data-rmse:35.8076\n",
      "Stopping. Best iteration:\n",
      "[1553]\ttrain-rmse:10.5047\tvalid_data-rmse:35.796\n",
      "\n",
      "fold n°6\n",
      "[0]\ttrain-rmse:90.599\tvalid_data-rmse:80.1846\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:65.9804\tvalid_data-rmse:62.5492\n",
      "[200]\ttrain-rmse:49.6484\tvalid_data-rmse:52.5258\n",
      "[300]\ttrain-rmse:38.4362\tvalid_data-rmse:46.813\n",
      "[400]\ttrain-rmse:30.5444\tvalid_data-rmse:43.9605\n",
      "[500]\ttrain-rmse:24.9892\tvalid_data-rmse:42.1534\n",
      "[600]\ttrain-rmse:20.9898\tvalid_data-rmse:41.356\n",
      "[700]\ttrain-rmse:18.0624\tvalid_data-rmse:40.7703\n",
      "[800]\ttrain-rmse:15.9092\tvalid_data-rmse:40.3988\n",
      "[900]\ttrain-rmse:14.3804\tvalid_data-rmse:40.2975\n",
      "[1000]\ttrain-rmse:13.268\tvalid_data-rmse:40.3086\n",
      "[1100]\ttrain-rmse:12.4394\tvalid_data-rmse:40.3483\n",
      "Stopping. Best iteration:\n",
      "[937]\ttrain-rmse:13.9404\tvalid_data-rmse:40.2741\n",
      "\n",
      "fold n°7\n",
      "[0]\ttrain-rmse:92.6089\tvalid_data-rmse:55.6578\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:67.6274\tvalid_data-rmse:44.1668\n",
      "[200]\ttrain-rmse:51.0244\tvalid_data-rmse:38.6979\n",
      "[300]\ttrain-rmse:39.1473\tvalid_data-rmse:36.38\n",
      "[400]\ttrain-rmse:30.9678\tvalid_data-rmse:35.583\n",
      "[500]\ttrain-rmse:25.1973\tvalid_data-rmse:35.7723\n",
      "[600]\ttrain-rmse:21.1505\tvalid_data-rmse:36.3546\n",
      "Stopping. Best iteration:\n",
      "[423]\ttrain-rmse:29.4135\tvalid_data-rmse:35.5121\n",
      "\n",
      "fold n°8\n",
      "[0]\ttrain-rmse:83.0717\tvalid_data-rmse:135.172\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:61.0821\tvalid_data-rmse:118.028\n",
      "[200]\ttrain-rmse:46.2274\tvalid_data-rmse:107.033\n",
      "[300]\ttrain-rmse:35.9936\tvalid_data-rmse:101.281\n",
      "[400]\ttrain-rmse:28.6882\tvalid_data-rmse:98.2538\n",
      "[500]\ttrain-rmse:23.5303\tvalid_data-rmse:96.6313\n",
      "[600]\ttrain-rmse:19.9182\tvalid_data-rmse:95.8731\n",
      "[700]\ttrain-rmse:17.2157\tvalid_data-rmse:95.4973\n",
      "[800]\ttrain-rmse:15.2016\tvalid_data-rmse:95.2814\n",
      "[900]\ttrain-rmse:13.7484\tvalid_data-rmse:95.217\n",
      "[1000]\ttrain-rmse:12.6791\tvalid_data-rmse:95.1649\n",
      "[1100]\ttrain-rmse:11.8923\tvalid_data-rmse:95.1646\n",
      "[1200]\ttrain-rmse:11.2899\tvalid_data-rmse:95.2543\n",
      "Stopping. Best iteration:\n",
      "[1004]\ttrain-rmse:12.6367\tvalid_data-rmse:95.1394\n",
      "\n",
      "fold n°9\n",
      "[0]\ttrain-rmse:91.5487\tvalid_data-rmse:69.8665\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:66.7656\tvalid_data-rmse:55.563\n",
      "[200]\ttrain-rmse:50.0734\tvalid_data-rmse:48.6881\n",
      "[300]\ttrain-rmse:38.5778\tvalid_data-rmse:45.3446\n",
      "[400]\ttrain-rmse:30.5053\tvalid_data-rmse:43.9029\n",
      "[500]\ttrain-rmse:24.7904\tvalid_data-rmse:43.4781\n",
      "[600]\ttrain-rmse:20.6632\tvalid_data-rmse:43.434\n",
      "[700]\ttrain-rmse:17.8024\tvalid_data-rmse:43.4393\n",
      "[800]\ttrain-rmse:15.7204\tvalid_data-rmse:43.4943\n",
      "Stopping. Best iteration:\n",
      "[668]\ttrain-rmse:18.6229\tvalid_data-rmse:43.3924\n",
      "\n",
      "fold n°10\n",
      "[0]\ttrain-rmse:90.5143\tvalid_data-rmse:81.258\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:66.4115\tvalid_data-rmse:62.363\n",
      "[200]\ttrain-rmse:49.7704\tvalid_data-rmse:52.57\n",
      "[300]\ttrain-rmse:38.4751\tvalid_data-rmse:48.6771\n",
      "[400]\ttrain-rmse:30.6349\tvalid_data-rmse:47.3114\n",
      "[500]\ttrain-rmse:24.8681\tvalid_data-rmse:47.9424\n",
      "[600]\ttrain-rmse:20.8041\tvalid_data-rmse:48.983\n",
      "Stopping. Best iteration:\n",
      "[416]\ttrain-rmse:29.5978\tvalid_data-rmse:47.2095\n",
      "\n",
      "CV score: 3078.34326010\n",
      "12.148204837149365\n",
      "cv smape: 1.3925897581425317\n",
      "validation: 27548.02399320236\n",
      "13.950460408550732\n",
      "1.3024769795724633\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 10}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb = np.zeros(len(train_array))\n",
    "predictions_xgb = np.zeros(len(test_array))\n",
    "valid_xgb=np.zeros(len(label_valid_array))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = xgb.DMatrix(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200,\n",
    "                    verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(train_array[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(test_array), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    valid_xgb += clf.predict(xgb.DMatrix(validtion_array), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, label_array)))\n",
    "print(\"cv smape:\",smape(oof_xgb, label_array))\n",
    "print('validation:',mean_squared_error(valid_xgb, label_valid_array))\n",
    "print(smape(valid_xgb,label_valid_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission_csv generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_id   ad_id  create_time  ad_size  ad_trades_id  commodity_type  \\\n",
      "0          1  394352   1529648412       34            84              13   \n",
      "1          2  585401   1553076190       40           221               1   \n",
      "2          3  419408   1553031394       30           122              13   \n",
      "3          4  405326   1553238836       64           136               1   \n",
      "4          5  578942   1541191585       34            12              13   \n",
      "\n",
      "   commodity_id  ad_account_id  \\\n",
      "0         29663          26657   \n",
      "1            -1           6262   \n",
      "2         32110          17436   \n",
      "3            -1          22359   \n",
      "4          6372          24082   \n",
      "\n",
      "                                         when_ad_put  \\\n",
      "0  281474976645120,281474976645120,28147497664512...   \n",
      "1  281474976579587,281474976579587,28147497657958...   \n",
      "2  17592185782272,17592185782272,17592185782272,1...   \n",
      "3  281474976694272,281474976694272,28147497669427...   \n",
      "4  68719214592,68719214592,68719214592,6871921459...   \n",
      "\n",
      "                                  audience_targeting  bid  \n",
      "0  age:819,608,988,741,202,837,400,394,942,361,72...  120  \n",
      "1  age:819,433,479,741,229,347,522,79,753,601|edu...   42  \n",
      "2                                                all    6  \n",
      "3  age:333,1|gender:2|area:11505,1874,3790,4566,5...  181  \n",
      "4  age:819,608,988,741,202,837,400,394,942,361,72...   31  \n",
      "how many ad_id exposure less 1 times :\n",
      "926\n",
      "Monotonic !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_sample=pd.read_csv(\"../Data/A_preliminary/testA/test_sample.dat\",header=None,sep='\\t',\n",
    "                        names=['sample_id','ad_id','create_time','ad_size','ad_trades_id','commodity_type','commodity_id','ad_account_id',\n",
    "                              'when_ad_put','audience_targeting','bid'])\n",
    "print(test_sample.head())\n",
    "submission=test_sample[['sample_id','ad_id','bid']]\n",
    "submission.insert(submission.shape[1], 'predict_exposure', predictions_xgb)\n",
    "# submission.insert(submission.shape[1], 'predict_exposure', predictions_lgb)\n",
    "\n",
    "submission['predict_exposure']=submission['predict_exposure'].apply(lambda x : round(x,4))\n",
    "ad_id_exposure_predic=submission.groupby(['ad_id'])['predict_exposure'].aggregate(['mean','max','min']).reset_index()\n",
    "ad_id_dict={}\n",
    "for ad_id,mean,min_,max_ in zip(ad_id_exposure_predic['ad_id'],ad_id_exposure_predic['mean'],ad_id_exposure_predic['min'],ad_id_exposure_predic['max']):\n",
    "#     ad_id_dict[ad_id]=mean-(max_-min_)/8\n",
    "    ad_id_dict[ad_id]=mean\n",
    "#     ad_id_dict[ad_id]=max_\n",
    "\n",
    "print('how many ad_id exposure less 1 times :')\n",
    "nums=0\n",
    "for _ in ad_id_dict.values():\n",
    "    if _ < 1:\n",
    "        nums+=1\n",
    "print(nums)\n",
    "\n",
    "print('Monotonic !!!')\n",
    "ad_id_explosure_df=pd.DataFrame({\"ad_id\":list(ad_id_dict.keys()),\"explosion_init\":list(ad_id_dict.values())})\n",
    "submission_csv=test_sample[['sample_id','ad_id','bid']][:]\n",
    "submission_csv=submission_csv.merge(ad_id_explosure_df,on='ad_id',how='outer')\n",
    "submission_csv['explosion']=submission_csv['explosion_init']+submission_csv['bid']/1000\n",
    "submission_csv['explosion']=submission_csv['explosion'].apply(lambda x:round(x,4))\n",
    "# submission_csv[['sample_id','explosion']].to_csv('submission.csv',header=None,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.71878838836866"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_csv['explosion'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv[['sample_id','explosion']].to_csv('submission_3_03_15_98.csv',header=None,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 45.0701\tvalid_1's rmse: 112.622\n",
      "[400]\ttraining's rmse: 39.6025\tvalid_1's rmse: 107.064\n",
      "[600]\ttraining's rmse: 36.2563\tvalid_1's rmse: 104.18\n",
      "[800]\ttraining's rmse: 33.7299\tvalid_1's rmse: 102.389\n",
      "[1000]\ttraining's rmse: 31.6861\tvalid_1's rmse: 100.994\n",
      "[1200]\ttraining's rmse: 30.0162\tvalid_1's rmse: 99.8082\n",
      "[1400]\ttraining's rmse: 28.5247\tvalid_1's rmse: 98.8732\n",
      "[1600]\ttraining's rmse: 27.23\tvalid_1's rmse: 98.0081\n",
      "[1800]\ttraining's rmse: 26.1293\tvalid_1's rmse: 97.4583\n",
      "[2000]\ttraining's rmse: 25.1362\tvalid_1's rmse: 97.0622\n",
      "[2200]\ttraining's rmse: 24.2459\tvalid_1's rmse: 96.7088\n",
      "[2400]\ttraining's rmse: 23.4227\tvalid_1's rmse: 96.4222\n",
      "[2600]\ttraining's rmse: 22.6961\tvalid_1's rmse: 96.2949\n",
      "[2800]\ttraining's rmse: 22.0008\tvalid_1's rmse: 96.2284\n",
      "[3000]\ttraining's rmse: 21.3848\tvalid_1's rmse: 96.1073\n",
      "[3200]\ttraining's rmse: 20.8178\tvalid_1's rmse: 96.1185\n",
      "Early stopping, best iteration is:\n",
      "[3068]\ttraining's rmse: 21.1932\tvalid_1's rmse: 96.0566\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 61.7209\tvalid_1's rmse: 58.1156\n",
      "[400]\ttraining's rmse: 54.1265\tvalid_1's rmse: 57.0292\n",
      "[600]\ttraining's rmse: 49.2841\tvalid_1's rmse: 56.7142\n",
      "[800]\ttraining's rmse: 45.652\tvalid_1's rmse: 56.3005\n",
      "[1000]\ttraining's rmse: 42.8964\tvalid_1's rmse: 56.3087\n",
      "[1200]\ttraining's rmse: 40.6269\tvalid_1's rmse: 56.1619\n",
      "[1400]\ttraining's rmse: 38.7742\tvalid_1's rmse: 56.0975\n",
      "[1600]\ttraining's rmse: 37.1468\tvalid_1's rmse: 56.1244\n",
      "Early stopping, best iteration is:\n",
      "[1471]\ttraining's rmse: 38.1847\tvalid_1's rmse: 56.0548\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 63.4526\tvalid_1's rmse: 50.7745\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's rmse: 64.6076\tvalid_1's rmse: 50.6285\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 64.3498\tvalid_1's rmse: 39.1248\n",
      "[400]\ttraining's rmse: 56.8549\tvalid_1's rmse: 34.967\n",
      "[600]\ttraining's rmse: 51.9685\tvalid_1's rmse: 32.4035\n",
      "[800]\ttraining's rmse: 48.1809\tvalid_1's rmse: 30.9735\n",
      "[1000]\ttraining's rmse: 45.1849\tvalid_1's rmse: 30.3772\n",
      "[1200]\ttraining's rmse: 42.7813\tvalid_1's rmse: 30.158\n",
      "[1400]\ttraining's rmse: 40.7493\tvalid_1's rmse: 30.2855\n",
      "Early stopping, best iteration is:\n",
      "[1203]\ttraining's rmse: 42.7509\tvalid_1's rmse: 30.1519\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 64.2814\tvalid_1's rmse: 42.6574\n",
      "[400]\ttraining's rmse: 55.9716\tvalid_1's rmse: 39.2808\n",
      "[600]\ttraining's rmse: 50.682\tvalid_1's rmse: 38.7341\n",
      "[800]\ttraining's rmse: 46.7973\tvalid_1's rmse: 38.9182\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttraining's rmse: 50.1385\tvalid_1's rmse: 38.621\n",
      "CV score: 3466.61991943\n",
      "validation: 19126.692065882457\n",
      "7.079067205458727\n",
      "1.6460466397270637\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_lgb = np.zeros(train_array.shape[0])\n",
    "predictions_lgb = np.zeros(test_array.shape[0])\n",
    "valid_lgb=np.zeros(len(label_valid_array))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = lgb.Dataset(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    num_round = 10000*(fold_+1)\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(train_array[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test_array, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    valid_lgb += clf.predict(validtion_array, ntree_limit=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, label_array)))\n",
    "print(\"cv smape:\",smape(oof_lgb, label_array))\n",
    "print('validation:',mean_squared_error(valid_lgb, label_valid_array))\n",
    "print(smape(valid_lgb,label_valid_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample=pd.read_csv(\"../Data/A_preliminary/testA/test_sample.dat\",header=None,sep='\\t',\n",
    "                        names=['sample_id','ad_id','create_time','ad_size','ad_trades_id','commodity_type','commodity_id','ad_account_id',\n",
    "                              'when_ad_put','audience_targeting','bid'])\n",
    "print(test_sample.head())\n",
    "submission=test_sample[['sample_id','ad_id','bid']]\n",
    "# submission.insert(submission.shape[1], 'predict_exposure', predictions_xgb)\n",
    "submission.insert(submission.shape[1], 'predict_exposure', predictions_lgb)\n",
    "\n",
    "submission['predict_exposure']=submission['predict_exposure'].apply(lambda x : round(x,4))\n",
    "ad_id_exposure_predic=submission.groupby(['ad_id'])['predict_exposure'].aggregate(['mean','max','min']).reset_index()\n",
    "ad_id_dict={}\n",
    "for ad_id,mean,min_,max_ in zip(ad_id_exposure_predic['ad_id'],ad_id_exposure_predic['mean'],ad_id_exposure_predic['min'],ad_id_exposure_predic['max']):\n",
    "#     ad_id_dict[ad_id]=mean-(max_-min_)/8\n",
    "    ad_id_dict[ad_id]=mean\n",
    "#     ad_id_dict[ad_id]=max_\n",
    "\n",
    "\n",
    "print('how many ad_id exposure less 1 times :')\n",
    "nums=0\n",
    "for _ in ad_id_dict.values():\n",
    "    if _ < 1:\n",
    "        nums+=1\n",
    "print(nums)\n",
    "\n",
    "print('Monotonic !!!')\n",
    "ad_id_explosure_df=pd.DataFrame({\"ad_id\":list(ad_id_dict.keys()),\"explosion_init\":list(ad_id_dict.values())})\n",
    "submission_csv=test_sample[['sample_id','ad_id','bid']][:]\n",
    "submission_csv=submission_csv.merge(ad_id_explosure_df,on='ad_id',how='outer')\n",
    "submission_csv['explosion']=submission_csv['explosion_init']+submission_csv['bid']/1000\n",
    "submission_csv['explosion']=submission_csv['explosion'].apply(lambda x:round(x,4))\n",
    "# submission_csv[['sample_id','explosion']].to_csv('submission.csv',header=None,index=None,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2SecondsFrom1970(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y-%m-%d %H:%M:%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return secondsFrom1970\n",
    "\n",
    "def seconds2Datetime(seconds_from_1970):\n",
    "    timeArray = time.localtime(seconds_from_1970)#1970秒数\n",
    "    otherStyleTime = time.strftime(\"%Y-%m-%d %H:%M:%S\", timeArray)\n",
    "    datetime1=datetime.datetime.strptime(otherStyleTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return str(datetime1)\n",
    "def datetime2SecondsFrom1970_s(timeDateStr:str):\n",
    "    time1=datetime.datetime.strptime(timeDateStr,\"%Y%m%d%H%M%S\")\n",
    "    secondsFrom1970=time.mktime(time1.timetuple())\n",
    "    return int(secondsFrom1970)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_sample_test=pd.read_csv('../Data/A_preliminary_generate/Test/ad_sample_feature2phase_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traint_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_3_19=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0319_feature2phase_train.csv')\n",
    "valid_set_from_3_19=train_set_3_19[:2000]#设定验证集\n",
    "train_set_3_19=train_set_3_19[2000:]\n",
    "train_set_3_18=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0318_feature2phase_train.csv')\n",
    "train_set_3_17=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0317_feature2phase_train.csv')\n",
    "train_set_3_16=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0316_feature2phase_train.csv')\n",
    "train_set_3_15=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0315_feature2phase_train.csv')\n",
    "train_set_3_14=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0314_feature2phase_train.csv')\n",
    "train_set_3_13=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0313_feature2phase_train.csv')\n",
    "train_set_3_12=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0312_feature2phase_train.csv')\n",
    "train_set_3_11=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0311_feature2phase_train.csv')\n",
    "train_set_3_10=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0310_feature2phase_train.csv')\n",
    "train_set_3_09=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0309_feature2phase_train.csv')\n",
    "train_set_3_08=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0308_feature2phase_train.csv')\n",
    "train_set_3_07=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0307_feature2phase_train.csv')\n",
    "train_set_3_06=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0306_feature2phase_train.csv')\n",
    "train_set_3_05=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0305_feature2phase_train.csv')\n",
    "train_set_3_04=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0304_feature2phase_train.csv')\n",
    "# train_set_3_03=pd.read_csv('../Data/A_preliminary_generate/Train/ad_sample_0303_feature1phase_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 236611 entries, 2000 to 18527\n",
      "Columns: 129 entries, ad_id to users_watch_ad_median\n",
      "dtypes: float64(53), int64(75), object(1)\n",
      "memory usage: 234.7+ MB\n",
      "train\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Columns: 129 entries, ad_id to users_watch_ad_median\n",
      "dtypes: float64(53), int64(75), object(1)\n",
      "memory usage: 2.0+ MB\n",
      "valid\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "train_set=pd.DataFrame([])\n",
    "train_set=pd.concat([train_set,train_set_3_19],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_18],axis=0)\n",
    "train_set['ad_trades_id']=train_set['ad_trades_id'].apply(lambda x: int(str(x).split(',')[0]))\n",
    "#3月18,19日两天有275条样本交易行业超过一个，但是test_sample中不存在这样的样本，直接取第一个\n",
    "train_set=pd.concat([train_set,train_set_3_17],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_16],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_15],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_14],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_13],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_12],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_11],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_10],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_09],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_08],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_07],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_06],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_05],axis=0)\n",
    "train_set=pd.concat([train_set,train_set_3_04],axis=0)\n",
    "# train_set=pd.concat([train_set,train_set_3_03],axis=0)\n",
    "print('train\\n',train_set.info())\n",
    "print('valid\\n',valid_set_from_3_19.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236611\n",
      "236611\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228871 entries, 0 to 228870\n",
      "Columns: 130 entries, index to users_watch_ad_median\n",
      "dtypes: float64(53), int64(76), object(1)\n",
      "memory usage: 227.0+ MB\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape[0])\n",
    "train_set.drop_duplicates(inplace=True)\n",
    "print(train_set.shape[0])#去重\n",
    "train_set=train_set[(train_set['hold_time']>10800)]#持续时间需要超过三个小时的样本\n",
    "# train_set=train_set[(train_set['audience_orientation_nums']>0)]#定向人群数量为0的是有问题的\n",
    "train_set.reset_index(inplace=True)\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation_set split  &  feature fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list=[\n",
    "# 'ad_id','audience_targeting','end_time','ad_account_id','commodity_id','commodity_type','ad_trades_id','ad_size','hold_time',\n",
    "#  'create_time','sample_id', 'exposure_ad_id',\n",
    " 'bid','audience_orientation_nums','0000_0030','0030_0100','0100_0130','0130_0200','0200_0230','0230_0300','0300_0330',\n",
    "'0330_0400','0400_0430','0430_0500','0500_0530','0530_0600','0600_0630','0630_0700','0700_0730','0730_0800','0800_0830','0830_0900',\n",
    "'0900_0930','0930_1000','1000_1030','1030_1100','1100_1130','1130_1200','1200_1230','1230_1300','1300_1330','1330_1400','1400_1430','1430_1500',\n",
    "'1500_1530','1530_1600','1600_1630','1630_1700','1700_1730','1730_1800','1800_1830','1830_1900','1900_1930','1930_2000','2000_2030','2030_2100',\n",
    "'2100_2130','2130_2200','2200_2230','2230_2300','2300_2330','2330_2400',\n",
    "'ad_id_history_exposure_times','ad_id_bid_mean','ad_id_bid_var','ad_id_pctr_mean','ad_id_pctr_var','ad_id_quality_ecpm_mean',\n",
    "'ad_id_quality_ecpm_var','ad_id_total_ecpm_mean','ad_id_total_ecpm_var', \n",
    "'account_id_history_exposure_times','account_id_bid_mean','account_id_bid_var','account_id_pctr_mean','account_id_pctr_var',\n",
    "'account_id_quality_ecpm_mean','account_id_quality_ecpm_var','account_id_total_ecpm_mean','account_id_total_ecpm_var',\n",
    "'commodity_id_history_exposure_times','commodity_id_bid_mean','commodity_id_bid_var','commodity_id_pctr_mean','commodity_id_pctr_var',\n",
    "'commodity_id_quality_ecpm_mean','commodity_id_quality_ecpm_var','commodity_id_total_ecpm_mean','commodity_id_total_ecpm_var',\n",
    "'commodity_type_history_exposure_times','commodity_type_bid_mean','commodity_type_bid_var','commodity_type_pctr_mean',\n",
    "'commodity_type_pctr_var','commodity_type_quality_ecpm_mean','commodity_type_quality_ecpm_var','commodity_type_total_ecpm_mean',\n",
    "'commodity_type_total_ecpm_var',\n",
    "'trades_id_history_exposure_times','trades_id_bid_mean','trades_id_bid_var','trades_id_pctr_mean','trades_id_pctr_var',\n",
    "'trades_id_quality_ecpm_mean','trades_id_quality_ecpm_var','trades_id_total_ecpm_mean','trades_id_total_ecpm_var',\n",
    "'week_day','have_create_seconds',\n",
    "#feature phase 2\n",
    "'have_create_days', 'history_exposure_times_mean', 'age_item_nums', 'gender_item_nums',\n",
    "'area_item_nums', 'status_item_nums', 'education_item_nums', 'consuption_ability_item_nums', 'device_item_nums',\n",
    "'work_item_nums', 'connection_type_item_nums', 'behavior_item_nums', 'day_before_exposure_times', 'users_watch_ad_sum',\n",
    "'users_watch_ad_mean', 'users_watch_ad_var', 'users_watch_ad_max', 'users_watch_ad_median'\n",
    "]\n",
    "train_set.sort_values(by=['ad_id','bid'],inplace=True)\n",
    "label=train_set['exposure_times']\n",
    "train=train_set[columns_list]\n",
    "test=ad_sample_test[columns_list]\n",
    "label_validtion=valid_set_from_3_19['exposure_times']\n",
    "validtion=valid_set_from_3_19[columns_list]\n",
    "\n",
    "label_valid_array=label_validtion.values\n",
    "validtion_array=validtion.values\n",
    "train_array=train.values\n",
    "label_array=label.values\n",
    "test_array=test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyier/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    biger_lesser_equation=(preds-labels)/(abs(preds-labels)+1e-16)\n",
    "    grad = biger_lesser_equation*(4*labels/(preds+labels)**2)\n",
    "    hess = (-1*biger_lesser_equation)*(8*labels/(preds+labels)**3)\n",
    "    return 10*grad, 10*hess\n",
    "def smape_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    temp_differ_abs=abs(preds-labels)\n",
    "    temp_sum_mod_2=(preds+labels)/2\n",
    "    return 'smape',sum(temp_differ_abs/temp_sum_mod_2)/labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(valid_,label_valid_array):\n",
    "    temp_differ_abs=abs(valid_-label_valid_array)\n",
    "    temp_sum_mod_2=(valid_+label_valid_array)/2\n",
    "    \n",
    "    print(40*(1-(sum(temp_differ_abs/temp_sum_mod_2)/label_valid_array.shape[0]/2)))\n",
    "    return sum(temp_differ_abs/temp_sum_mod_2)/label_valid_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:93.2532\tvalid_data-rmse:73.2176\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 500 rounds.\n",
      "[100]\ttrain-rmse:67.6709\tvalid_data-rmse:57.7957\n",
      "[200]\ttrain-rmse:50.7466\tvalid_data-rmse:51.8199\n",
      "[300]\ttrain-rmse:39.3162\tvalid_data-rmse:50.688\n",
      "[400]\ttrain-rmse:31.1207\tvalid_data-rmse:52.0763\n",
      "[500]\ttrain-rmse:25.5119\tvalid_data-rmse:53.8399\n",
      "[600]\ttrain-rmse:21.2966\tvalid_data-rmse:55.4909\n",
      "[700]\ttrain-rmse:18.1942\tvalid_data-rmse:56.749\n",
      "Stopping. Best iteration:\n",
      "[296]\ttrain-rmse:39.7284\tvalid_data-rmse:50.6804\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:86.1643\tvalid_data-rmse:102.321\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 500 rounds.\n",
      "[100]\ttrain-rmse:62.2939\tvalid_data-rmse:84.4392\n",
      "[200]\ttrain-rmse:46.6221\tvalid_data-rmse:74.5544\n",
      "[300]\ttrain-rmse:35.9749\tvalid_data-rmse:69.5759\n",
      "[400]\ttrain-rmse:28.5406\tvalid_data-rmse:66.3823\n",
      "[500]\ttrain-rmse:23.263\tvalid_data-rmse:64.2416\n",
      "[600]\ttrain-rmse:19.6074\tvalid_data-rmse:63.1288\n",
      "[700]\ttrain-rmse:16.9115\tvalid_data-rmse:61.909\n",
      "[800]\ttrain-rmse:15.0455\tvalid_data-rmse:61.5451\n",
      "[900]\ttrain-rmse:13.6204\tvalid_data-rmse:61.0289\n",
      "[1000]\ttrain-rmse:12.595\tvalid_data-rmse:60.6448\n",
      "[1100]\ttrain-rmse:11.8109\tvalid_data-rmse:60.5594\n",
      "[1200]\ttrain-rmse:11.2611\tvalid_data-rmse:60.527\n",
      "[1300]\ttrain-rmse:10.8374\tvalid_data-rmse:60.378\n",
      "[1400]\ttrain-rmse:10.5124\tvalid_data-rmse:60.3273\n",
      "[1500]\ttrain-rmse:10.2797\tvalid_data-rmse:60.3561\n",
      "[1600]\ttrain-rmse:10.0605\tvalid_data-rmse:60.4178\n",
      "[1700]\ttrain-rmse:9.87684\tvalid_data-rmse:60.4786\n",
      "[1800]\ttrain-rmse:9.70513\tvalid_data-rmse:60.4769\n",
      "[1900]\ttrain-rmse:9.54175\tvalid_data-rmse:60.5265\n",
      "Stopping. Best iteration:\n",
      "[1460]\ttrain-rmse:10.3664\tvalid_data-rmse:60.2816\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:88.7116\tvalid_data-rmse:93.0659\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 500 rounds.\n",
      "[100]\ttrain-rmse:64.5602\tvalid_data-rmse:75.8917\n",
      "[200]\ttrain-rmse:48.4852\tvalid_data-rmse:70.392\n",
      "[300]\ttrain-rmse:37.137\tvalid_data-rmse:71.1111\n",
      "[400]\ttrain-rmse:29.2527\tvalid_data-rmse:73.936\n",
      "[500]\ttrain-rmse:23.584\tvalid_data-rmse:76.8965\n",
      "[600]\ttrain-rmse:19.6353\tvalid_data-rmse:79.7461\n",
      "[700]\ttrain-rmse:16.8126\tvalid_data-rmse:82.2737\n",
      "Stopping. Best iteration:\n",
      "[244]\ttrain-rmse:43.0409\tvalid_data-rmse:70.2117\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:92.1704\tvalid_data-rmse:78.5116\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 500 rounds.\n",
      "[100]\ttrain-rmse:67.241\tvalid_data-rmse:62.0104\n",
      "[200]\ttrain-rmse:50.4253\tvalid_data-rmse:53.8806\n",
      "[300]\ttrain-rmse:38.9845\tvalid_data-rmse:50.3305\n",
      "[400]\ttrain-rmse:30.8133\tvalid_data-rmse:48.9041\n",
      "[500]\ttrain-rmse:25.0675\tvalid_data-rmse:48.5333\n",
      "[600]\ttrain-rmse:20.8977\tvalid_data-rmse:48.4508\n",
      "[700]\ttrain-rmse:17.8694\tvalid_data-rmse:48.5706\n",
      "[800]\ttrain-rmse:15.6455\tvalid_data-rmse:48.7886\n",
      "[900]\ttrain-rmse:14.0847\tvalid_data-rmse:48.9902\n",
      "[1000]\ttrain-rmse:12.8955\tvalid_data-rmse:49.1959\n",
      "Stopping. Best iteration:\n",
      "[589]\ttrain-rmse:21.2879\tvalid_data-rmse:48.4247\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:87.4192\tvalid_data-rmse:97.8681\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 500 rounds.\n",
      "[100]\ttrain-rmse:63.2269\tvalid_data-rmse:87.0262\n",
      "[200]\ttrain-rmse:47.1468\tvalid_data-rmse:81.9643\n",
      "[300]\ttrain-rmse:36.2649\tvalid_data-rmse:79.2778\n",
      "[400]\ttrain-rmse:28.7049\tvalid_data-rmse:78.1336\n",
      "[500]\ttrain-rmse:23.3802\tvalid_data-rmse:77.8367\n",
      "[600]\ttrain-rmse:19.6668\tvalid_data-rmse:77.5605\n",
      "[700]\ttrain-rmse:16.9387\tvalid_data-rmse:77.4433\n",
      "[800]\ttrain-rmse:15.0172\tvalid_data-rmse:77.4436\n",
      "[900]\ttrain-rmse:13.5682\tvalid_data-rmse:77.4372\n",
      "[1000]\ttrain-rmse:12.5901\tvalid_data-rmse:77.5163\n",
      "[1100]\ttrain-rmse:11.8758\tvalid_data-rmse:77.6022\n",
      "[1200]\ttrain-rmse:11.3062\tvalid_data-rmse:77.7022\n",
      "[1300]\ttrain-rmse:10.9018\tvalid_data-rmse:77.8003\n",
      "Stopping. Best iteration:\n",
      "[856]\ttrain-rmse:14.163\tvalid_data-rmse:77.3983\n",
      "\n",
      "CV score: 3893.49267901\n",
      "7.978830581052478\n",
      "cv smape: 1.601058470947376\n",
      "validation: 22239.86052916551\n",
      "8.769627568041072\n",
      "1.5615186215979464\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 10}\n",
    "# xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "#            'silent': True, 'nthread': 10}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "oof_xgb = np.zeros(len(train_array))\n",
    "predictions_xgb = np.zeros(len(test_array))\n",
    "valid_xgb=np.zeros(len(label_valid_array))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = xgb.DMatrix(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "#     clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=500,\n",
    "#                     verbose_eval=100, params=xgb_params,obj=smape_obj,feval=smape_eval)\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=500,\n",
    "                    verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(train_array[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(test_array), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    valid_xgb += clf.predict(xgb.DMatrix(validtion_array), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, label_array)))\n",
    "print(\"cv smape:\",smape(oof_xgb, label_array))\n",
    "print('validation:',mean_squared_error(valid_xgb, label_valid_array))\n",
    "print(smape(valid_xgb,label_valid_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample=pd.read_csv(\"../Data/A_preliminary/testA/test_sample.dat\",header=None,sep='\\t',\n",
    "                        names=['sample_id','ad_id','create_time','ad_size','ad_trades_id','commodity_type','commodity_id','ad_account_id',\n",
    "                              'when_ad_put','audience_targeting','bid'])\n",
    "print(test_sample.head())\n",
    "submission=test_sample[['sample_id','ad_id','bid']]\n",
    "submission.insert(submission.shape[1], 'predict_exposure', predictions_xgb)\n",
    "# submission.insert(submission.shape[1], 'predict_exposure', predictions_lgb)\n",
    "\n",
    "submission['predict_exposure']=submission['predict_exposure'].apply(lambda x : round(x,4))\n",
    "ad_id_exposure_predic=submission.groupby(['ad_id'])['predict_exposure'].aggregate(['mean','max','min']).reset_index()\n",
    "ad_id_dict={}\n",
    "for ad_id,mean,min_,max_ in zip(ad_id_exposure_predic['ad_id'],ad_id_exposure_predic['mean'],ad_id_exposure_predic['min'],ad_id_exposure_predic['max']):\n",
    "#     ad_id_dict[ad_id]=mean-(max_-min_)/8\n",
    "    ad_id_dict[ad_id]=mean\n",
    "#     ad_id_dict[ad_id]=max_\n",
    "\n",
    "print('how many ad_id exposure less 1 times :')\n",
    "nums=0\n",
    "for _ in ad_id_dict.values():\n",
    "    if _ < 1:\n",
    "        nums+=1\n",
    "print(nums)\n",
    "print('submission_csv mean',submission_csv['explosion'].mean())\n",
    "\n",
    "print('Monotonic adjust!!!')\n",
    "ad_id_explosure_df=pd.DataFrame({\"ad_id\":list(ad_id_dict.keys()),\"explosion_init\":list(ad_id_dict.values())})\n",
    "submission_csv=test_sample[['sample_id','ad_id','bid']][:]\n",
    "submission_csv=submission_csv.merge(ad_id_explosure_df,on='ad_id',how='outer')\n",
    "submission_csv['explosion']=submission_csv['explosion_init']+submission_csv['bid']/1000\n",
    "submission_csv['explosion']=submission_csv['explosion'].apply(lambda x:round(x,4))\n",
    "# submission_csv[['sample_id','explosion']].to_csv('submission.csv',header=None,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
